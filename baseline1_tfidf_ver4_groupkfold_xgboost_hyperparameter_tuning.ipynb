{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db58bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ec8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n",
      "3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeng_sun\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import lightgbm\n",
    "\n",
    "print(sklearn.__version__)\n",
    "print(lightgbm.__version__)\n",
    "\n",
    "## log into wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8746d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/test_essays.csv')\n",
    "sub = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/sample_submission.csv')\n",
    "org_train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/train_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774cc0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/daigt/train_v2_drcat_02.csv', sep=',')\n",
    "display(train.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b3f5c",
   "metadata": {},
   "source": [
    "#### Read and append the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950181df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18894, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_gen_data = pd.read_parquet('/home/peng_sun2/s3shared/kaggle/llm-2023/external_data/gen_data_21122023.parquet')\n",
    "display(train_gen_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8ff17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates(subset = ['text'])\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "\n",
    "### append the generated data\n",
    "# train = pd.concat([train, train_gen_data], axis = 0).reset_index(drop = True)\n",
    "# display(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96d7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train.loc[train['label'] ==0, :].reset_index(drop = True)\n",
    "train_1 = train.loc[train['label'] ==1, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ce322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27371, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff76121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17497, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a54b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_length = min(len(train_0), len(train_1))\n",
    "# min_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4035fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_train= pd.DataFrame()\n",
    "# for i in tqdm(range(min_length), total = min_length):\n",
    "#     sorted_train = pd.concat([sorted_train, pd.DataFrame(train_0.iloc[i,:]).T], axis = 0)\n",
    "#     sorted_train = pd.concat([sorted_train, pd.DataFrame(train_1.iloc[i,:]).T], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856d300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(train_0) > min_length:\n",
    "#     sorted_train = pd.concat([sorted_train, train_0.iloc[min_length:, :]], axis = 0)\n",
    "# elif len(train_1) > min_length:\n",
    "#     sorted_train = pd.concat([sorted_train, train_1.iloc[min_length:, :]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aadc4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def sort_train(train):\n",
    "    train_0 = train.loc[train['label'] ==0, :].reset_index(drop = True)\n",
    "    train_1 = train.loc[train['label'] ==1, :].reset_index(drop = True)\n",
    "    \n",
    "    min_length = min(len(train_0), len(train_1))\n",
    "    \n",
    "    sorted_train= pd.DataFrame()\n",
    "    for i in tqdm(range(min_length), total = min_length):\n",
    "        sorted_train = pd.concat([sorted_train, pd.DataFrame(train_0.iloc[i,:]).T], axis = 0)\n",
    "        sorted_train = pd.concat([sorted_train, pd.DataFrame(train_1.iloc[i,:]).T], axis = 0)\n",
    "    \n",
    "    if len(train_0) > min_length:\n",
    "        sorted_train = pd.concat([sorted_train, train_0.iloc[min_length:, :]], axis = 0)\n",
    "    elif len(train_1) > min_length:\n",
    "        sorted_train = pd.concat([sorted_train, train_1.iloc[min_length:, :]], axis = 0)\n",
    "        \n",
    "    del train_0, train_1, train\n",
    "    sorted_train['label'] = sorted_train['label'].astype(np.int32)\n",
    "    return sorted_train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b1faa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cell phone use should not be legal while drivi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phones and Driving\\n\\nDriving is a good way to...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PHONES AND DRIVING\\n\\nIn this world in which w...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>People are debating whether if drivers should ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texting and driving\\n\\nOver half of drivers in...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Phones\\n\\nModern humans today are always on th...      0   \n",
       "1  This essay will explain if drivers should or s...      0   \n",
       "2  Driving while the use of cellular devices\\n\\nT...      0   \n",
       "3  Phones & Driving\\n\\nDrivers should not be able...      0   \n",
       "4  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n",
       "5  Cell phone use should not be legal while drivi...      0   \n",
       "6  Phones and Driving\\n\\nDriving is a good way to...      0   \n",
       "7  PHONES AND DRIVING\\n\\nIn this world in which w...      0   \n",
       "8  People are debating whether if drivers should ...      0   \n",
       "9  Texting and driving\\n\\nOver half of drivers in...      0   \n",
       "\n",
       "          prompt_name           source  RDizzl3_seven  \n",
       "0  Phones and driving  persuade_corpus          False  \n",
       "1  Phones and driving  persuade_corpus          False  \n",
       "2  Phones and driving  persuade_corpus          False  \n",
       "3  Phones and driving  persuade_corpus          False  \n",
       "4  Phones and driving  persuade_corpus          False  \n",
       "5  Phones and driving  persuade_corpus          False  \n",
       "6  Phones and driving  persuade_corpus          False  \n",
       "7  Phones and driving  persuade_corpus          False  \n",
       "8  Phones and driving  persuade_corpus          False  \n",
       "9  Phones and driving  persuade_corpus          False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train.shape)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce464667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17497/17497 [00:45<00:00, 383.98it/s]\n"
     ]
    }
   ],
   "source": [
    "train = sort_train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20f4501c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In recent years, technology has had a profoun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>mistral7binstruct_v2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I strongly believe that meditation and mindful...</td>\n",
       "      <td>1</td>\n",
       "      <td>Distance learning</td>\n",
       "      <td>llama_70b_v1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One way school administrators can attempt to c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cell phones at school</td>\n",
       "      <td>chat_gpt_moth</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>While summer is meant as a break from the regu...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer projects</td>\n",
       "      <td>darragh_claude_v7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The use of Facial Action Coding System (FACS) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facial action coding system</td>\n",
       "      <td>darragh_claude_v6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Phones\\n\\nModern humans today are always on th...      0   \n",
       "1   In recent years, technology has had a profoun...      1   \n",
       "2  This essay will explain if drivers should or s...      0   \n",
       "3  I strongly believe that meditation and mindful...      1   \n",
       "4  Driving while the use of cellular devices\\n\\nT...      0   \n",
       "5  One way school administrators can attempt to c...      1   \n",
       "6  Phones & Driving\\n\\nDrivers should not be able...      0   \n",
       "7  While summer is meant as a break from the regu...      1   \n",
       "8  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n",
       "9  The use of Facial Action Coding System (FACS) ...      1   \n",
       "\n",
       "                   prompt_name                source RDizzl3_seven  \n",
       "0           Phones and driving       persuade_corpus         False  \n",
       "1              Car-free cities  mistral7binstruct_v2          True  \n",
       "2           Phones and driving       persuade_corpus         False  \n",
       "3            Distance learning          llama_70b_v1         False  \n",
       "4           Phones and driving       persuade_corpus         False  \n",
       "5        Cell phones at school         chat_gpt_moth         False  \n",
       "6           Phones and driving       persuade_corpus         False  \n",
       "7              Summer projects     darragh_claude_v7         False  \n",
       "8           Phones and driving       persuade_corpus         False  \n",
       "9  Facial action coding system     darragh_claude_v6          True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train.shape)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f647664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWERCASE = False\n",
    "VOCAB_SIZE = 30522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9b4831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create byte-pair encoding tokenizer\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token='[UNK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb8ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding normalization and pre_tokenizer\n",
    "raw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()]+ [normalizers.Lowercase()] if LOWERCASE else [])\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f33614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding special tokens and creating trainer instance\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size = VOCAB_SIZE, special_tokens = special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08980728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/pyarrow/pandas_compat.py:358: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1748.84it/s]\n",
      "100%|██████████| 44868/44868 [02:03<00:00, 362.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating huggingface dataset object\n",
    "dataset = Dataset.from_pandas(test[['text']])\n",
    "def train_corp_iter():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i:i+1000]['text']\n",
    "raw_tokenizer.train_from_iterator(train_corp_iter(), trainer = trainer)\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "tokenized_texts_test = []\n",
    "for text in tqdm(test['text'].tolist()):\n",
    "    tokenized_texts_test.append(tokenizer.tokenize(text))\n",
    "\n",
    "tokenized_texts_train = []\n",
    "\n",
    "for text in tqdm(train['text'].tolist()):\n",
    "    tokenized_texts_train.append(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f7ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ĠBbb', 'Ġccc', 'Ġddd', '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93001dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c63bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ĠAaa Ġbbb Ġccc': 0, 'Ġbbb Ġccc .': 6, 'ĠAaa Ġbbb Ġccc .': 1, 'ĠBbb Ġccc Ġddd': 2, 'Ġccc Ġddd .': 7, 'ĠBbb Ġccc Ġddd .': 3, 'ĠCCC Ġddd Ġeee': 4, 'Ġddd Ġeee .': 8, 'ĠCCC Ġddd Ġeee .': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (3, 5), lowercase=False, sublinear_tf = True, analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None,\n",
    "                            strip_accents = 'unicode',\n",
    "                            dtype = np.float32)\n",
    "vectorizer.fit(tokenized_texts_test)\n",
    "\n",
    "# Getting vocab\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, \n",
    "                             #vocabulary=vocab,\n",
    "                            analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None, strip_accents='unicode',\n",
    "                            dtype = np.float32\n",
    "                            )\n",
    "\n",
    "tf_train = vectorizer.fit_transform(tokenized_texts_train)\n",
    "tf_test = vectorizer.transform(tokenized_texts_test)\n",
    "## get the vocabulary of the training dataset\n",
    "train_vocab = vectorizer.vocabulary_\n",
    "\n",
    "del vectorizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7a56d",
   "metadata": {},
   "source": [
    "### Convert the type from numpy.float64 to numpy.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff0482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# ## convert data for tf_train\n",
    "# data  = tf_train.data.astype(np.float16)\n",
    "# indices = tf_train.indices\n",
    "# indptr = tf_train.indptr\n",
    "# tf_train = csr_matrix((data, indices, indptr), shape = tf_train.shape)\n",
    "\n",
    "\n",
    "# ## convert data for tf_test\n",
    "# data = tf_test.data.astype(np.float16)\n",
    "# indices = tf_test.indices\n",
    "# indptr = tf_test.indptr\n",
    "# tf_test = csr_matrix((data, indices, indptr), shape = tf_test.shape)\n",
    "\n",
    "# del data, indices, indptr\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0209d0a",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c0db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### save train_vocab\n",
    "# import joblib\n",
    "# model_path = '/home/peng_sun2/s3shared/kaggle/llm-2023/baseline1/'\n",
    "# joblib.dump(train_vocab, f'{model_path}vocab_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3c74dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: z97en3lz\n",
      "Sweep URL: https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Check if it's in scoring stage\n",
    "# if len(test.text.values) <= 5:\n",
    "#     # if not, just sample submission\n",
    "#     sub.to_csv('submission.csv', index=False)\n",
    "# else:\n",
    "# otherwise, run fitting process\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {'name': 'validatoin_auc', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'max_depth': {'min': 3, 'max': 100},\n",
    "        'min_child_weight': {'min': 1, 'max': 10},\n",
    "        'gamma': {'min': 0, 'max': 10},\n",
    "        'subsample': {'min': 0.5, 'max': 1.0},\n",
    "        'colsample_bytree': {'min': 0.5, 'max': 1.0},\n",
    "        'lambda_value': {'min': 0.0, 'max': 2.0},\n",
    "        'alpha': {'min': 0.0, 'max': 2.0},\n",
    "        'num_boost_round': {'min': 100, 'max': 2000}\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"llm-2023-xgboost-hyperparameter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5954df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_range_into_parts(start, end, num_parts):\n",
    "    splits = np.linspace(start, end, num_parts + 1)\n",
    "    ranges = [(int(np.floor(splits[i])), int(np.ceil(splits[i + 1]))) for i in range(num_parts)]\n",
    "    return np.array(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d2730d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_train_catboost(tf_train, y_train, cat, num_parts):\n",
    "    split_ranges = split_range_into_parts(0, tf_train.shape[0], num_parts);\n",
    "    #print(split_ranges)\n",
    "    \n",
    "    ## incrementally train catboost\n",
    "    for i, (start, end) in enumerate(split_ranges):\n",
    "        print('start, end ', start, ' ', end)\n",
    "        train_X_split = tf_train[start:end, :]\n",
    "        train_y_split = y_train[start:end]\n",
    "        \n",
    "        #print(train_X_split.shape, train_y_split.shape)\n",
    "        if i ==0:\n",
    "            cat.fit(train_X_split, train_y_split)\n",
    "        else: \n",
    "            cat.fit(train_X_split, train_y_split, init_model = cat)\n",
    "        print(f'part {i} is finished ...')\n",
    "    return cat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7941cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33c9be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9851b6",
   "metadata": {},
   "source": [
    "## Test xgboost code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cde6ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedGroupKFold\n",
    "# from sklearn import metrics\n",
    "\n",
    "# skf = StratifiedGroupKFold(n_splits = 5)\n",
    "# skf.get_n_splits(tf_train, y_train, groups =train['prompt_name'])\n",
    "\n",
    "# for i, (train_idx, test_idx) in enumerate(skf.split(tf_train, y_train, groups = train['prompt_name'])):\n",
    "#     train_X = tf_train[train_idx]\n",
    "#     eval_X = tf_train[test_idx];\n",
    "#     train_y = y_train[train_idx]\n",
    "#     eval_y = y_train[test_idx];\n",
    "#     break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba9b1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain = xgb.DMatrix(train_X, label = train_y)\n",
    "# deval = xgb.DMatrix(eval_X, label=eval_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f384b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up your training parameters\n",
    "# param = {\n",
    "#     'max_depth': 3,  # the maximum depth of each tree\n",
    "#     'eta': 0.3,  # the training step for each iteration\n",
    "#     'objective': 'binary:logistic',  # binary classification\n",
    "#     'eval_metric': 'logloss'  # evaluation metric\n",
    "# }\n",
    "# num_round = 100  # the number of training iterations\n",
    "\n",
    "# bst = xgb.train(\n",
    "#     param,\n",
    "#     dtrain,\n",
    "#     num_round, \n",
    "#     evals = [(deval, 'eval')],\n",
    "#     early_stopping_rounds=10\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00599c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_preds = bst.predict(deval)\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(eval_y, eval_preds, pos_label = 1)\n",
    "# eval_auc = metrics.auc(fpr, tpr)\n",
    "# eval_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030e1a4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c317d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 63ma531g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 1.0279020505010756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.7517210944198072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_value: 0.08785536439422348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 63\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_boost_round: 1503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.9297162741284126\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240109_122752-63ma531g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/63ma531g' target=\"_blank\">super-sweep-1</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/63ma531g' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/63ma531g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:0.43342\n",
      "[1]\teval-rmse:0.36955\n",
      "[2]\teval-rmse:0.32718\n",
      "[3]\teval-rmse:0.30072\n",
      "[4]\teval-rmse:0.28151\n",
      "[5]\teval-rmse:0.26845\n",
      "[6]\teval-rmse:0.26110\n",
      "[7]\teval-rmse:0.25586\n",
      "[8]\teval-rmse:0.25117\n",
      "[9]\teval-rmse:0.24814\n",
      "[10]\teval-rmse:0.24567\n",
      "[11]\teval-rmse:0.24390\n",
      "[12]\teval-rmse:0.24229\n",
      "[13]\teval-rmse:0.24176\n",
      "[14]\teval-rmse:0.24080\n",
      "[15]\teval-rmse:0.23947\n",
      "[16]\teval-rmse:0.23950\n",
      "[17]\teval-rmse:0.23952\n",
      "[18]\teval-rmse:0.23952\n",
      "[19]\teval-rmse:0.23950\n",
      "[20]\teval-rmse:0.23949\n",
      "[21]\teval-rmse:0.23951\n",
      "[22]\teval-rmse:0.23955\n",
      "[23]\teval-rmse:0.23951\n",
      "[24]\teval-rmse:0.23953\n",
      "[25]\teval-rmse:0.23955\n",
      "[26]\teval-rmse:0.23957\n",
      "[27]\teval-rmse:0.23953\n",
      "[28]\teval-rmse:0.23951\n",
      "[29]\teval-rmse:0.23951\n",
      "[30]\teval-rmse:0.23954\n",
      "[31]\teval-rmse:0.23956\n",
      "[32]\teval-rmse:0.23958\n",
      "[33]\teval-rmse:0.23956\n",
      "[34]\teval-rmse:0.23954\n",
      "[35]\teval-rmse:0.23954\n",
      "[36]\teval-rmse:0.23952\n",
      "[37]\teval-rmse:0.23954\n",
      "[38]\teval-rmse:0.23953\n",
      "[39]\teval-rmse:0.23951\n",
      "[40]\teval-rmse:0.23952\n",
      "[41]\teval-rmse:0.23950\n",
      "[42]\teval-rmse:0.23946\n",
      "[43]\teval-rmse:0.23948\n",
      "[44]\teval-rmse:0.23949\n",
      "[45]\teval-rmse:0.23951\n",
      "[46]\teval-rmse:0.23919\n",
      "[47]\teval-rmse:0.23919\n",
      "[48]\teval-rmse:0.23919\n",
      "[49]\teval-rmse:0.23919\n",
      "[50]\teval-rmse:0.23920\n",
      "[51]\teval-rmse:0.23918\n",
      "[52]\teval-rmse:0.23918\n",
      "[53]\teval-rmse:0.23918\n",
      "[54]\teval-rmse:0.23920\n",
      "[55]\teval-rmse:0.23921\n",
      "[56]\teval-rmse:0.23917\n",
      "[57]\teval-rmse:0.23919\n",
      "[58]\teval-rmse:0.23919\n",
      "[59]\teval-rmse:0.23922\n",
      "[60]\teval-rmse:0.23919\n",
      "[61]\teval-rmse:0.23918\n",
      "[62]\teval-rmse:0.23914\n",
      "[63]\teval-rmse:0.23914\n",
      "[64]\teval-rmse:0.23917\n",
      "[65]\teval-rmse:0.23919\n",
      "[66]\teval-rmse:0.23919\n",
      "[67]\teval-rmse:0.23919\n",
      "[68]\teval-rmse:0.23918\n",
      "[69]\teval-rmse:0.23917\n",
      "[70]\teval-rmse:0.23923\n",
      "[71]\teval-rmse:0.23924\n",
      "[72]\teval-rmse:0.23922\n",
      "[73]\teval-rmse:0.23920\n",
      "[74]\teval-rmse:0.23917\n",
      "[75]\teval-rmse:0.23920\n",
      "[76]\teval-rmse:0.23917\n",
      "[77]\teval-rmse:0.23919\n",
      "[78]\teval-rmse:0.23920\n",
      "[79]\teval-rmse:0.23919\n",
      "[80]\teval-rmse:0.23920\n",
      "[81]\teval-rmse:0.23920\n",
      "[82]\teval-rmse:0.23923\n",
      "[83]\teval-rmse:0.23922\n",
      "[84]\teval-rmse:0.23922\n",
      "[85]\teval-rmse:0.23921\n",
      "[86]\teval-rmse:0.23922\n",
      "[87]\teval-rmse:0.23924\n",
      "[88]\teval-rmse:0.23924\n",
      "[89]\teval-rmse:0.23923\n",
      "[90]\teval-rmse:0.23923\n",
      "[91]\teval-rmse:0.23921\n",
      "[92]\teval-rmse:0.23919\n",
      "[93]\teval-rmse:0.23919\n",
      "[94]\teval-rmse:0.23923\n",
      "[95]\teval-rmse:0.23924\n",
      "[96]\teval-rmse:0.23925\n",
      "[97]\teval-rmse:0.23920\n",
      "[98]\teval-rmse:0.23920\n",
      "[99]\teval-rmse:0.23919\n",
      "[100]\teval-rmse:0.23923\n",
      "[101]\teval-rmse:0.23923\n",
      "[102]\teval-rmse:0.23920\n",
      "[103]\teval-rmse:0.23919\n",
      "[104]\teval-rmse:0.23920\n",
      "[105]\teval-rmse:0.23922\n",
      "[106]\teval-rmse:0.23920\n",
      "[107]\teval-rmse:0.23920\n",
      "[108]\teval-rmse:0.23916\n",
      "[109]\teval-rmse:0.23914\n",
      "[110]\teval-rmse:0.23915\n",
      "[111]\teval-rmse:0.23917\n",
      "[112]\teval-rmse:0.23917\n",
      "[113]\teval-rmse:0.23920\n",
      "[114]\teval-rmse:0.23921\n",
      "[115]\teval-rmse:0.23921\n",
      "[116]\teval-rmse:0.23921\n",
      "[117]\teval-rmse:0.23921\n",
      "[118]\teval-rmse:0.23921\n",
      "[119]\teval-rmse:0.23921\n",
      "[120]\teval-rmse:0.23922\n",
      "[121]\teval-rmse:0.23920\n",
      "[122]\teval-rmse:0.23923\n",
      "[123]\teval-rmse:0.23920\n",
      "[124]\teval-rmse:0.23926\n",
      "[125]\teval-rmse:0.23924\n",
      "[126]\teval-rmse:0.23921\n",
      "[127]\teval-rmse:0.23920\n",
      "[128]\teval-rmse:0.23924\n",
      "[129]\teval-rmse:0.23920\n",
      "[130]\teval-rmse:0.23918\n",
      "[131]\teval-rmse:0.23918\n",
      "[132]\teval-rmse:0.23917\n",
      "[133]\teval-rmse:0.23920\n",
      "[134]\teval-rmse:0.23922\n",
      "[135]\teval-rmse:0.23920\n",
      "[136]\teval-rmse:0.23922\n",
      "[137]\teval-rmse:0.23921\n",
      "[138]\teval-rmse:0.23921\n",
      "[139]\teval-rmse:0.23921\n",
      "[140]\teval-rmse:0.23922\n",
      "[141]\teval-rmse:0.23918\n",
      "[142]\teval-rmse:0.23917\n",
      "[143]\teval-rmse:0.23920\n",
      "[144]\teval-rmse:0.23918\n",
      "[145]\teval-rmse:0.23919\n",
      "[146]\teval-rmse:0.23920\n",
      "[147]\teval-rmse:0.23918\n",
      "[148]\teval-rmse:0.23919\n",
      "[149]\teval-rmse:0.23915\n",
      "[150]\teval-rmse:0.23916\n",
      "[151]\teval-rmse:0.23919\n",
      "[152]\teval-rmse:0.23922\n",
      "[153]\teval-rmse:0.23922\n",
      "[154]\teval-rmse:0.23923\n",
      "[155]\teval-rmse:0.23921\n",
      "[156]\teval-rmse:0.23921\n",
      "[157]\teval-rmse:0.23920\n",
      "[158]\teval-rmse:0.23922\n",
      "[159]\teval-rmse:0.23919\n",
      "[160]\teval-rmse:0.23919\n",
      "[161]\teval-rmse:0.23917\n",
      "[0]\teval-rmse:0.38626\n",
      "[1]\teval-rmse:0.33549\n",
      "[2]\teval-rmse:0.30166\n",
      "[3]\teval-rmse:0.28483\n",
      "[4]\teval-rmse:0.27265\n",
      "[5]\teval-rmse:0.26587\n",
      "[6]\teval-rmse:0.26325\n",
      "[7]\teval-rmse:0.25882\n",
      "[8]\teval-rmse:0.25682\n",
      "[9]\teval-rmse:0.25601\n",
      "[10]\teval-rmse:0.25554\n",
      "[11]\teval-rmse:0.25460\n",
      "[12]\teval-rmse:0.25231\n",
      "[13]\teval-rmse:0.25229\n",
      "[14]\teval-rmse:0.25002\n",
      "[15]\teval-rmse:0.24981\n",
      "[16]\teval-rmse:0.24980\n",
      "[17]\teval-rmse:0.24980\n",
      "[18]\teval-rmse:0.24980\n",
      "[19]\teval-rmse:0.24982\n",
      "[20]\teval-rmse:0.24980\n",
      "[21]\teval-rmse:0.24895\n",
      "[22]\teval-rmse:0.24896\n",
      "[23]\teval-rmse:0.24895\n",
      "[24]\teval-rmse:0.24896\n",
      "[25]\teval-rmse:0.24825\n",
      "[26]\teval-rmse:0.24825\n",
      "[27]\teval-rmse:0.24826\n",
      "[28]\teval-rmse:0.24825\n",
      "[29]\teval-rmse:0.24826\n",
      "[30]\teval-rmse:0.24825\n",
      "[31]\teval-rmse:0.24825\n",
      "[32]\teval-rmse:0.24825\n",
      "[33]\teval-rmse:0.24825\n",
      "[34]\teval-rmse:0.24825\n",
      "[35]\teval-rmse:0.24826\n",
      "[36]\teval-rmse:0.24826\n",
      "[37]\teval-rmse:0.24826\n",
      "[38]\teval-rmse:0.24827\n",
      "[39]\teval-rmse:0.24826\n",
      "[40]\teval-rmse:0.24826\n",
      "[41]\teval-rmse:0.24825\n",
      "[42]\teval-rmse:0.24825\n",
      "[43]\teval-rmse:0.24826\n",
      "[44]\teval-rmse:0.24826\n",
      "[45]\teval-rmse:0.24825\n",
      "[46]\teval-rmse:0.24825\n",
      "[47]\teval-rmse:0.24824\n",
      "[48]\teval-rmse:0.24825\n",
      "[49]\teval-rmse:0.24826\n",
      "[50]\teval-rmse:0.24826\n",
      "[51]\teval-rmse:0.24825\n",
      "[52]\teval-rmse:0.24824\n",
      "[53]\teval-rmse:0.24824\n",
      "[54]\teval-rmse:0.24824\n",
      "[55]\teval-rmse:0.24824\n",
      "[56]\teval-rmse:0.24825\n",
      "[57]\teval-rmse:0.24825\n",
      "[58]\teval-rmse:0.24826\n",
      "[59]\teval-rmse:0.24826\n",
      "[60]\teval-rmse:0.24826\n",
      "[61]\teval-rmse:0.24826\n",
      "[62]\teval-rmse:0.24825\n",
      "[63]\teval-rmse:0.24826\n",
      "[64]\teval-rmse:0.24824\n",
      "[65]\teval-rmse:0.24824\n",
      "[66]\teval-rmse:0.24825\n",
      "[67]\teval-rmse:0.24826\n",
      "[68]\teval-rmse:0.24826\n",
      "[69]\teval-rmse:0.24826\n",
      "[70]\teval-rmse:0.24826\n",
      "[71]\teval-rmse:0.24827\n",
      "[72]\teval-rmse:0.24827\n",
      "[73]\teval-rmse:0.24826\n",
      "[74]\teval-rmse:0.24825\n",
      "[75]\teval-rmse:0.24825\n",
      "[76]\teval-rmse:0.24826\n",
      "[77]\teval-rmse:0.24825\n",
      "[78]\teval-rmse:0.24825\n",
      "[79]\teval-rmse:0.24824\n",
      "[80]\teval-rmse:0.24825\n",
      "[81]\teval-rmse:0.24825\n",
      "[82]\teval-rmse:0.24825\n",
      "[83]\teval-rmse:0.24825\n",
      "[84]\teval-rmse:0.24823\n",
      "[85]\teval-rmse:0.24823\n",
      "[86]\teval-rmse:0.24824\n",
      "[87]\teval-rmse:0.24824\n",
      "[88]\teval-rmse:0.24823\n",
      "[89]\teval-rmse:0.24824\n",
      "[90]\teval-rmse:0.24823\n",
      "[91]\teval-rmse:0.24825\n",
      "[92]\teval-rmse:0.24825\n",
      "[93]\teval-rmse:0.24825\n",
      "[94]\teval-rmse:0.24824\n",
      "[95]\teval-rmse:0.24824\n",
      "[96]\teval-rmse:0.24825\n",
      "[97]\teval-rmse:0.24825\n",
      "[98]\teval-rmse:0.24824\n",
      "[99]\teval-rmse:0.24824\n",
      "[100]\teval-rmse:0.24824\n",
      "[101]\teval-rmse:0.24825\n",
      "[102]\teval-rmse:0.24825\n",
      "[103]\teval-rmse:0.24825\n",
      "[104]\teval-rmse:0.24826\n",
      "[105]\teval-rmse:0.24825\n",
      "[106]\teval-rmse:0.24825\n",
      "[107]\teval-rmse:0.24825\n",
      "[108]\teval-rmse:0.24825\n",
      "[109]\teval-rmse:0.24824\n",
      "[110]\teval-rmse:0.24825\n",
      "[111]\teval-rmse:0.24825\n",
      "[112]\teval-rmse:0.24827\n",
      "[113]\teval-rmse:0.24827\n",
      "[114]\teval-rmse:0.24826\n",
      "[115]\teval-rmse:0.24826\n",
      "[116]\teval-rmse:0.24828\n",
      "[117]\teval-rmse:0.24827\n",
      "[118]\teval-rmse:0.24826\n",
      "[119]\teval-rmse:0.24826\n",
      "[120]\teval-rmse:0.24827\n",
      "[121]\teval-rmse:0.24826\n",
      "[122]\teval-rmse:0.24826\n",
      "[123]\teval-rmse:0.24826\n",
      "[124]\teval-rmse:0.24825\n",
      "[125]\teval-rmse:0.24825\n",
      "[126]\teval-rmse:0.24826\n",
      "[127]\teval-rmse:0.24826\n",
      "[128]\teval-rmse:0.24825\n",
      "[129]\teval-rmse:0.24825\n",
      "[130]\teval-rmse:0.24826\n",
      "[131]\teval-rmse:0.24825\n",
      "[132]\teval-rmse:0.24826\n",
      "[133]\teval-rmse:0.24824\n",
      "[134]\teval-rmse:0.24826\n",
      "[135]\teval-rmse:0.24827\n",
      "[136]\teval-rmse:0.24827\n",
      "[137]\teval-rmse:0.24827\n",
      "[138]\teval-rmse:0.24827\n",
      "[139]\teval-rmse:0.24827\n",
      "[140]\teval-rmse:0.24827\n",
      "[141]\teval-rmse:0.24826\n",
      "[142]\teval-rmse:0.24826\n",
      "[143]\teval-rmse:0.24827\n",
      "[144]\teval-rmse:0.24827\n",
      "[145]\teval-rmse:0.24827\n",
      "[146]\teval-rmse:0.24827\n",
      "[147]\teval-rmse:0.24826\n",
      "[148]\teval-rmse:0.24826\n",
      "[149]\teval-rmse:0.24826\n",
      "[150]\teval-rmse:0.24826\n",
      "[151]\teval-rmse:0.24825\n",
      "[152]\teval-rmse:0.24825\n",
      "[153]\teval-rmse:0.24824\n",
      "[154]\teval-rmse:0.24825\n",
      "[155]\teval-rmse:0.24824\n",
      "[156]\teval-rmse:0.24824\n",
      "[157]\teval-rmse:0.24824\n",
      "[158]\teval-rmse:0.24824\n",
      "[159]\teval-rmse:0.24824\n",
      "[160]\teval-rmse:0.24825\n",
      "[161]\teval-rmse:0.24825\n",
      "[162]\teval-rmse:0.24825\n",
      "[163]\teval-rmse:0.24826\n",
      "[164]\teval-rmse:0.24826\n",
      "[165]\teval-rmse:0.24827\n",
      "[166]\teval-rmse:0.24827\n",
      "[167]\teval-rmse:0.24826\n",
      "[168]\teval-rmse:0.24826\n",
      "[169]\teval-rmse:0.24827\n",
      "[170]\teval-rmse:0.24827\n",
      "[171]\teval-rmse:0.24827\n",
      "[172]\teval-rmse:0.24828\n",
      "[173]\teval-rmse:0.24828\n",
      "[174]\teval-rmse:0.24827\n",
      "[175]\teval-rmse:0.24827\n",
      "[176]\teval-rmse:0.24828\n",
      "[177]\teval-rmse:0.24828\n",
      "[178]\teval-rmse:0.24826\n",
      "[179]\teval-rmse:0.24825\n",
      "[180]\teval-rmse:0.24825\n",
      "[181]\teval-rmse:0.24823\n",
      "[182]\teval-rmse:0.24823\n",
      "[183]\teval-rmse:0.24823\n",
      "[184]\teval-rmse:0.24823\n",
      "[185]\teval-rmse:0.24825\n",
      "[186]\teval-rmse:0.24826\n",
      "[187]\teval-rmse:0.24826\n",
      "[188]\teval-rmse:0.24826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189]\teval-rmse:0.24826\n",
      "[190]\teval-rmse:0.24827\n",
      "[191]\teval-rmse:0.24827\n",
      "[192]\teval-rmse:0.24827\n",
      "[193]\teval-rmse:0.24827\n",
      "[194]\teval-rmse:0.24826\n",
      "[195]\teval-rmse:0.24826\n",
      "[196]\teval-rmse:0.24826\n",
      "[197]\teval-rmse:0.24826\n",
      "[198]\teval-rmse:0.24826\n",
      "[199]\teval-rmse:0.24827\n",
      "[200]\teval-rmse:0.24825\n",
      "[201]\teval-rmse:0.24824\n",
      "[202]\teval-rmse:0.24827\n",
      "[203]\teval-rmse:0.24827\n",
      "[204]\teval-rmse:0.24827\n",
      "[205]\teval-rmse:0.24826\n",
      "[206]\teval-rmse:0.24826\n",
      "[207]\teval-rmse:0.24827\n",
      "[208]\teval-rmse:0.24826\n",
      "[209]\teval-rmse:0.24826\n",
      "[210]\teval-rmse:0.24828\n",
      "[211]\teval-rmse:0.24827\n",
      "[212]\teval-rmse:0.24826\n",
      "[213]\teval-rmse:0.24826\n",
      "[214]\teval-rmse:0.24826\n",
      "[215]\teval-rmse:0.24825\n",
      "[216]\teval-rmse:0.24825\n",
      "[217]\teval-rmse:0.24825\n",
      "[218]\teval-rmse:0.24826\n",
      "[219]\teval-rmse:0.24825\n",
      "[220]\teval-rmse:0.24825\n",
      "[221]\teval-rmse:0.24826\n",
      "[222]\teval-rmse:0.24826\n",
      "[223]\teval-rmse:0.24823\n",
      "[224]\teval-rmse:0.24823\n",
      "[225]\teval-rmse:0.24822\n",
      "[226]\teval-rmse:0.24823\n",
      "[227]\teval-rmse:0.24823\n",
      "[228]\teval-rmse:0.24823\n",
      "[229]\teval-rmse:0.24825\n",
      "[230]\teval-rmse:0.24824\n",
      "[231]\teval-rmse:0.24823\n",
      "[232]\teval-rmse:0.24824\n",
      "[233]\teval-rmse:0.24824\n",
      "[234]\teval-rmse:0.24825\n",
      "[235]\teval-rmse:0.24825\n",
      "[236]\teval-rmse:0.24823\n",
      "[237]\teval-rmse:0.24824\n",
      "[238]\teval-rmse:0.24823\n",
      "[239]\teval-rmse:0.24824\n",
      "[240]\teval-rmse:0.24825\n",
      "[241]\teval-rmse:0.24824\n",
      "[242]\teval-rmse:0.24825\n",
      "[243]\teval-rmse:0.24826\n",
      "[244]\teval-rmse:0.24826\n",
      "[245]\teval-rmse:0.24825\n",
      "[246]\teval-rmse:0.24826\n",
      "[247]\teval-rmse:0.24826\n",
      "[248]\teval-rmse:0.24826\n",
      "[249]\teval-rmse:0.24826\n",
      "[250]\teval-rmse:0.24826\n",
      "[251]\teval-rmse:0.24826\n",
      "[252]\teval-rmse:0.24825\n",
      "[253]\teval-rmse:0.24826\n",
      "[254]\teval-rmse:0.24826\n",
      "[255]\teval-rmse:0.24826\n",
      "[256]\teval-rmse:0.24826\n",
      "[257]\teval-rmse:0.24826\n",
      "[258]\teval-rmse:0.24826\n",
      "[259]\teval-rmse:0.24826\n",
      "[260]\teval-rmse:0.24827\n",
      "[261]\teval-rmse:0.24826\n",
      "[262]\teval-rmse:0.24826\n",
      "[263]\teval-rmse:0.24824\n",
      "[264]\teval-rmse:0.24824\n",
      "[265]\teval-rmse:0.24825\n",
      "[266]\teval-rmse:0.24825\n",
      "[267]\teval-rmse:0.24826\n",
      "[268]\teval-rmse:0.24826\n",
      "[269]\teval-rmse:0.24826\n",
      "[270]\teval-rmse:0.24827\n",
      "[271]\teval-rmse:0.24828\n",
      "[272]\teval-rmse:0.24827\n",
      "[273]\teval-rmse:0.24828\n",
      "[274]\teval-rmse:0.24827\n",
      "[275]\teval-rmse:0.24826\n",
      "[276]\teval-rmse:0.24825\n",
      "[277]\teval-rmse:0.24827\n",
      "[278]\teval-rmse:0.24827\n",
      "[279]\teval-rmse:0.24827\n",
      "[280]\teval-rmse:0.24826\n",
      "[281]\teval-rmse:0.24826\n",
      "[282]\teval-rmse:0.24826\n",
      "[283]\teval-rmse:0.24826\n",
      "[284]\teval-rmse:0.24826\n",
      "[285]\teval-rmse:0.24826\n",
      "[286]\teval-rmse:0.24826\n",
      "[287]\teval-rmse:0.24825\n",
      "[288]\teval-rmse:0.24828\n",
      "[289]\teval-rmse:0.24828\n",
      "[290]\teval-rmse:0.24829\n",
      "[291]\teval-rmse:0.24828\n",
      "[292]\teval-rmse:0.24829\n",
      "[293]\teval-rmse:0.24828\n",
      "[294]\teval-rmse:0.24826\n",
      "[295]\teval-rmse:0.24824\n",
      "[296]\teval-rmse:0.24824\n",
      "[297]\teval-rmse:0.24823\n",
      "[298]\teval-rmse:0.24824\n",
      "[299]\teval-rmse:0.24824\n",
      "[300]\teval-rmse:0.24824\n",
      "[301]\teval-rmse:0.24824\n",
      "[302]\teval-rmse:0.24825\n",
      "[303]\teval-rmse:0.24824\n",
      "[304]\teval-rmse:0.24825\n",
      "[305]\teval-rmse:0.24825\n",
      "[306]\teval-rmse:0.24826\n",
      "[307]\teval-rmse:0.24826\n",
      "[308]\teval-rmse:0.24827\n",
      "[309]\teval-rmse:0.24827\n",
      "[310]\teval-rmse:0.24826\n",
      "[311]\teval-rmse:0.24825\n",
      "[312]\teval-rmse:0.24824\n",
      "[313]\teval-rmse:0.24824\n",
      "[314]\teval-rmse:0.24824\n",
      "[315]\teval-rmse:0.24825\n",
      "[316]\teval-rmse:0.24825\n",
      "[317]\teval-rmse:0.24825\n",
      "[318]\teval-rmse:0.24825\n",
      "[319]\teval-rmse:0.24825\n",
      "[320]\teval-rmse:0.24825\n",
      "[321]\teval-rmse:0.24826\n",
      "[322]\teval-rmse:0.24825\n",
      "[323]\teval-rmse:0.24825\n",
      "[324]\teval-rmse:0.24825\n",
      "[0]\teval-rmse:0.41615\n",
      "[1]\teval-rmse:0.35141\n",
      "[2]\teval-rmse:0.30932\n",
      "[3]\teval-rmse:0.28403\n",
      "[4]\teval-rmse:0.26887\n",
      "[5]\teval-rmse:0.26084\n",
      "[6]\teval-rmse:0.25390\n",
      "[7]\teval-rmse:0.24923\n",
      "[8]\teval-rmse:0.24692\n",
      "[9]\teval-rmse:0.24386\n",
      "[10]\teval-rmse:0.24240\n",
      "[11]\teval-rmse:0.24139\n",
      "[12]\teval-rmse:0.23987\n",
      "[13]\teval-rmse:0.23924\n",
      "[14]\teval-rmse:0.23840\n",
      "[15]\teval-rmse:0.23829\n",
      "[16]\teval-rmse:0.23757\n",
      "[17]\teval-rmse:0.23766\n",
      "[18]\teval-rmse:0.23766\n",
      "[19]\teval-rmse:0.23766\n",
      "[20]\teval-rmse:0.23765\n",
      "[21]\teval-rmse:0.23765\n",
      "[22]\teval-rmse:0.23765\n",
      "[23]\teval-rmse:0.23765\n",
      "[24]\teval-rmse:0.23765\n",
      "[25]\teval-rmse:0.23765\n",
      "[26]\teval-rmse:0.23765\n",
      "[27]\teval-rmse:0.23765\n",
      "[28]\teval-rmse:0.23766\n",
      "[29]\teval-rmse:0.23766\n",
      "[30]\teval-rmse:0.23766\n",
      "[31]\teval-rmse:0.23766\n",
      "[32]\teval-rmse:0.23767\n",
      "[33]\teval-rmse:0.23766\n",
      "[34]\teval-rmse:0.23765\n",
      "[35]\teval-rmse:0.23766\n",
      "[36]\teval-rmse:0.23766\n",
      "[37]\teval-rmse:0.23766\n",
      "[38]\teval-rmse:0.23766\n",
      "[39]\teval-rmse:0.23766\n",
      "[40]\teval-rmse:0.23766\n",
      "[41]\teval-rmse:0.23765\n",
      "[42]\teval-rmse:0.23765\n",
      "[43]\teval-rmse:0.23765\n",
      "[44]\teval-rmse:0.23765\n",
      "[45]\teval-rmse:0.23765\n",
      "[46]\teval-rmse:0.23765\n",
      "[47]\teval-rmse:0.23765\n",
      "[48]\teval-rmse:0.23765\n",
      "[49]\teval-rmse:0.23766\n",
      "[50]\teval-rmse:0.23766\n",
      "[51]\teval-rmse:0.23765\n",
      "[52]\teval-rmse:0.23766\n",
      "[53]\teval-rmse:0.23766\n",
      "[54]\teval-rmse:0.23766\n",
      "[55]\teval-rmse:0.23766\n",
      "[56]\teval-rmse:0.23766\n",
      "[57]\teval-rmse:0.23766\n",
      "[58]\teval-rmse:0.23766\n",
      "[59]\teval-rmse:0.23766\n",
      "[60]\teval-rmse:0.23766\n",
      "[61]\teval-rmse:0.23766\n",
      "[62]\teval-rmse:0.23766\n",
      "[63]\teval-rmse:0.23765\n",
      "[64]\teval-rmse:0.23766\n",
      "[65]\teval-rmse:0.23766\n",
      "[66]\teval-rmse:0.23766\n",
      "[67]\teval-rmse:0.23766\n",
      "[68]\teval-rmse:0.23767\n",
      "[69]\teval-rmse:0.23766\n",
      "[70]\teval-rmse:0.23766\n",
      "[71]\teval-rmse:0.23765\n",
      "[72]\teval-rmse:0.23766\n",
      "[73]\teval-rmse:0.23766\n",
      "[74]\teval-rmse:0.23766\n",
      "[75]\teval-rmse:0.23766\n",
      "[76]\teval-rmse:0.23767\n",
      "[77]\teval-rmse:0.23767\n",
      "[78]\teval-rmse:0.23767\n",
      "[79]\teval-rmse:0.23767\n",
      "[80]\teval-rmse:0.23767\n",
      "[81]\teval-rmse:0.23767\n",
      "[82]\teval-rmse:0.23766\n",
      "[83]\teval-rmse:0.23766\n",
      "[84]\teval-rmse:0.23766\n",
      "[85]\teval-rmse:0.23766\n",
      "[86]\teval-rmse:0.23766\n",
      "[87]\teval-rmse:0.23766\n",
      "[88]\teval-rmse:0.23765\n",
      "[89]\teval-rmse:0.23766\n",
      "[90]\teval-rmse:0.23766\n",
      "[91]\teval-rmse:0.23766\n",
      "[92]\teval-rmse:0.23766\n",
      "[93]\teval-rmse:0.23766\n",
      "[94]\teval-rmse:0.23766\n",
      "[95]\teval-rmse:0.23766\n",
      "[96]\teval-rmse:0.23765\n",
      "[97]\teval-rmse:0.23765\n",
      "[98]\teval-rmse:0.23766\n",
      "[99]\teval-rmse:0.23766\n",
      "[100]\teval-rmse:0.23765\n",
      "[101]\teval-rmse:0.23766\n",
      "[102]\teval-rmse:0.23766\n",
      "[103]\teval-rmse:0.23766\n",
      "[104]\teval-rmse:0.23765\n",
      "[105]\teval-rmse:0.23766\n",
      "[106]\teval-rmse:0.23765\n",
      "[107]\teval-rmse:0.23766\n",
      "[108]\teval-rmse:0.23767\n",
      "[109]\teval-rmse:0.23766\n",
      "[110]\teval-rmse:0.23766\n",
      "[111]\teval-rmse:0.23766\n",
      "[112]\teval-rmse:0.23766\n",
      "[113]\teval-rmse:0.23766\n",
      "[114]\teval-rmse:0.23766\n",
      "[115]\teval-rmse:0.23766\n",
      "[116]\teval-rmse:0.23765\n",
      "[0]\teval-rmse:0.41314\n",
      "[1]\teval-rmse:0.36640\n",
      "[2]\teval-rmse:0.34198\n",
      "[3]\teval-rmse:0.32661\n",
      "[4]\teval-rmse:0.31462\n",
      "[5]\teval-rmse:0.31053\n",
      "[6]\teval-rmse:0.30510\n",
      "[7]\teval-rmse:0.30457\n",
      "[8]\teval-rmse:0.30500\n",
      "[9]\teval-rmse:0.30428\n",
      "[10]\teval-rmse:0.30394\n",
      "[11]\teval-rmse:0.30093\n",
      "[12]\teval-rmse:0.30119\n",
      "[13]\teval-rmse:0.30009\n",
      "[14]\teval-rmse:0.29861\n",
      "[15]\teval-rmse:0.29793\n",
      "[16]\teval-rmse:0.29739\n",
      "[17]\teval-rmse:0.29640\n",
      "[18]\teval-rmse:0.29640\n",
      "[19]\teval-rmse:0.29641\n",
      "[20]\teval-rmse:0.29641\n",
      "[21]\teval-rmse:0.29641\n",
      "[22]\teval-rmse:0.29642\n",
      "[23]\teval-rmse:0.29642\n",
      "[24]\teval-rmse:0.29642\n",
      "[25]\teval-rmse:0.29642\n",
      "[26]\teval-rmse:0.29642\n",
      "[27]\teval-rmse:0.29642\n",
      "[28]\teval-rmse:0.29642\n",
      "[29]\teval-rmse:0.29643\n",
      "[30]\teval-rmse:0.29643\n",
      "[31]\teval-rmse:0.29643\n",
      "[32]\teval-rmse:0.29643\n",
      "[33]\teval-rmse:0.29640\n",
      "[34]\teval-rmse:0.29640\n",
      "[35]\teval-rmse:0.29642\n",
      "[36]\teval-rmse:0.29641\n",
      "[37]\teval-rmse:0.29641\n",
      "[38]\teval-rmse:0.29641\n",
      "[39]\teval-rmse:0.29640\n",
      "[40]\teval-rmse:0.29640\n",
      "[41]\teval-rmse:0.29640\n",
      "[42]\teval-rmse:0.29642\n",
      "[43]\teval-rmse:0.29642\n",
      "[44]\teval-rmse:0.29639\n",
      "[45]\teval-rmse:0.29641\n",
      "[46]\teval-rmse:0.29641\n",
      "[47]\teval-rmse:0.29640\n",
      "[48]\teval-rmse:0.29641\n",
      "[49]\teval-rmse:0.29641\n",
      "[50]\teval-rmse:0.29641\n",
      "[51]\teval-rmse:0.29641\n",
      "[52]\teval-rmse:0.29640\n",
      "[53]\teval-rmse:0.29640\n",
      "[54]\teval-rmse:0.29638\n",
      "[55]\teval-rmse:0.29640\n",
      "[56]\teval-rmse:0.29640\n",
      "[57]\teval-rmse:0.29640\n",
      "[58]\teval-rmse:0.29640\n",
      "[59]\teval-rmse:0.29640\n",
      "[60]\teval-rmse:0.29640\n",
      "[61]\teval-rmse:0.29639\n",
      "[62]\teval-rmse:0.29640\n",
      "[63]\teval-rmse:0.29653\n",
      "[64]\teval-rmse:0.29653\n",
      "[65]\teval-rmse:0.29653\n",
      "[66]\teval-rmse:0.29653\n",
      "[67]\teval-rmse:0.29654\n",
      "[68]\teval-rmse:0.29652\n",
      "[69]\teval-rmse:0.29652\n",
      "[70]\teval-rmse:0.29652\n",
      "[71]\teval-rmse:0.29653\n",
      "[72]\teval-rmse:0.29655\n",
      "[73]\teval-rmse:0.29654\n",
      "[74]\teval-rmse:0.29655\n",
      "[75]\teval-rmse:0.29655\n",
      "[76]\teval-rmse:0.29655\n",
      "[77]\teval-rmse:0.29656\n",
      "[78]\teval-rmse:0.29655\n",
      "[79]\teval-rmse:0.29654\n",
      "[80]\teval-rmse:0.29654\n",
      "[81]\teval-rmse:0.29654\n",
      "[82]\teval-rmse:0.29654\n",
      "[83]\teval-rmse:0.29653\n",
      "[84]\teval-rmse:0.29653\n",
      "[85]\teval-rmse:0.29654\n",
      "[86]\teval-rmse:0.29654\n",
      "[87]\teval-rmse:0.29654\n",
      "[88]\teval-rmse:0.29654\n",
      "[89]\teval-rmse:0.29654\n",
      "[90]\teval-rmse:0.29654\n",
      "[91]\teval-rmse:0.29653\n",
      "[92]\teval-rmse:0.29654\n",
      "[93]\teval-rmse:0.29653\n",
      "[94]\teval-rmse:0.29653\n",
      "[95]\teval-rmse:0.29651\n",
      "[96]\teval-rmse:0.29652\n",
      "[97]\teval-rmse:0.29654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\teval-rmse:0.29654\n",
      "[99]\teval-rmse:0.29653\n",
      "[100]\teval-rmse:0.29652\n",
      "[101]\teval-rmse:0.29653\n",
      "[102]\teval-rmse:0.29654\n",
      "[103]\teval-rmse:0.29654\n",
      "[104]\teval-rmse:0.29654\n",
      "[105]\teval-rmse:0.29655\n",
      "[106]\teval-rmse:0.29656\n",
      "[107]\teval-rmse:0.29655\n",
      "[108]\teval-rmse:0.29655\n",
      "[109]\teval-rmse:0.29655\n",
      "[110]\teval-rmse:0.29654\n",
      "[111]\teval-rmse:0.29654\n",
      "[112]\teval-rmse:0.29654\n",
      "[113]\teval-rmse:0.29655\n",
      "[114]\teval-rmse:0.29654\n",
      "[115]\teval-rmse:0.29654\n",
      "[116]\teval-rmse:0.29653\n",
      "[117]\teval-rmse:0.29654\n",
      "[118]\teval-rmse:0.29654\n",
      "[119]\teval-rmse:0.29655\n",
      "[120]\teval-rmse:0.29656\n",
      "[121]\teval-rmse:0.29656\n",
      "[122]\teval-rmse:0.29657\n",
      "[123]\teval-rmse:0.29657\n",
      "[124]\teval-rmse:0.29657\n",
      "[125]\teval-rmse:0.29657\n",
      "[126]\teval-rmse:0.29657\n",
      "[127]\teval-rmse:0.29657\n",
      "[128]\teval-rmse:0.29655\n",
      "[129]\teval-rmse:0.29655\n",
      "[130]\teval-rmse:0.29654\n",
      "[131]\teval-rmse:0.29655\n",
      "[132]\teval-rmse:0.29654\n",
      "[133]\teval-rmse:0.29656\n",
      "[134]\teval-rmse:0.29656\n",
      "[135]\teval-rmse:0.29654\n",
      "[136]\teval-rmse:0.29653\n",
      "[137]\teval-rmse:0.29655\n",
      "[138]\teval-rmse:0.29655\n",
      "[139]\teval-rmse:0.29655\n",
      "[140]\teval-rmse:0.29656\n",
      "[141]\teval-rmse:0.29655\n",
      "[142]\teval-rmse:0.29654\n",
      "[143]\teval-rmse:0.29654\n",
      "[144]\teval-rmse:0.29653\n",
      "[145]\teval-rmse:0.29654\n",
      "[146]\teval-rmse:0.29654\n",
      "[147]\teval-rmse:0.29653\n",
      "[148]\teval-rmse:0.29655\n",
      "[149]\teval-rmse:0.29654\n",
      "[150]\teval-rmse:0.29654\n",
      "[151]\teval-rmse:0.29653\n",
      "[152]\teval-rmse:0.29654\n",
      "[153]\teval-rmse:0.29654\n",
      "[0]\teval-rmse:0.38911\n",
      "[1]\teval-rmse:0.33505\n",
      "[2]\teval-rmse:0.30155\n",
      "[3]\teval-rmse:0.28325\n",
      "[4]\teval-rmse:0.26849\n",
      "[5]\teval-rmse:0.25918\n",
      "[6]\teval-rmse:0.25454\n",
      "[7]\teval-rmse:0.25020\n",
      "[8]\teval-rmse:0.24852\n",
      "[9]\teval-rmse:0.24588\n",
      "[10]\teval-rmse:0.24411\n",
      "[11]\teval-rmse:0.24343\n",
      "[12]\teval-rmse:0.24325\n",
      "[13]\teval-rmse:0.24331\n",
      "[14]\teval-rmse:0.24196\n",
      "[15]\teval-rmse:0.24098\n",
      "[16]\teval-rmse:0.24099\n",
      "[17]\teval-rmse:0.24099\n",
      "[18]\teval-rmse:0.24148\n",
      "[19]\teval-rmse:0.24145\n",
      "[20]\teval-rmse:0.24144\n",
      "[21]\teval-rmse:0.24141\n",
      "[22]\teval-rmse:0.24141\n",
      "[23]\teval-rmse:0.24140\n",
      "[24]\teval-rmse:0.24140\n",
      "[25]\teval-rmse:0.24138\n",
      "[26]\teval-rmse:0.24141\n",
      "[27]\teval-rmse:0.24141\n",
      "[28]\teval-rmse:0.24142\n",
      "[29]\teval-rmse:0.24143\n",
      "[30]\teval-rmse:0.24141\n",
      "[31]\teval-rmse:0.24141\n",
      "[32]\teval-rmse:0.24142\n",
      "[33]\teval-rmse:0.24142\n",
      "[34]\teval-rmse:0.24144\n",
      "[35]\teval-rmse:0.24143\n",
      "[36]\teval-rmse:0.24143\n",
      "[37]\teval-rmse:0.24144\n",
      "[38]\teval-rmse:0.24145\n",
      "[39]\teval-rmse:0.24144\n",
      "[40]\teval-rmse:0.24146\n",
      "[41]\teval-rmse:0.24144\n",
      "[42]\teval-rmse:0.24146\n",
      "[43]\teval-rmse:0.24144\n",
      "[44]\teval-rmse:0.24145\n",
      "[45]\teval-rmse:0.24140\n",
      "[46]\teval-rmse:0.24139\n",
      "[47]\teval-rmse:0.24139\n",
      "[48]\teval-rmse:0.24140\n",
      "[49]\teval-rmse:0.24141\n",
      "[50]\teval-rmse:0.24142\n",
      "[51]\teval-rmse:0.24145\n",
      "[52]\teval-rmse:0.24145\n",
      "[53]\teval-rmse:0.24145\n",
      "[54]\teval-rmse:0.24142\n",
      "[55]\teval-rmse:0.24141\n",
      "[56]\teval-rmse:0.24141\n",
      "[57]\teval-rmse:0.24144\n",
      "[58]\teval-rmse:0.24144\n",
      "[59]\teval-rmse:0.24144\n",
      "[60]\teval-rmse:0.24142\n",
      "[61]\teval-rmse:0.24144\n",
      "[62]\teval-rmse:0.24145\n",
      "[63]\teval-rmse:0.24145\n",
      "[64]\teval-rmse:0.24144\n",
      "[65]\teval-rmse:0.24147\n",
      "[66]\teval-rmse:0.24144\n",
      "[67]\teval-rmse:0.24145\n",
      "[68]\teval-rmse:0.24147\n",
      "[69]\teval-rmse:0.24146\n",
      "[70]\teval-rmse:0.24145\n",
      "[71]\teval-rmse:0.24144\n",
      "[72]\teval-rmse:0.24145\n",
      "[73]\teval-rmse:0.24144\n",
      "[74]\teval-rmse:0.24143\n",
      "[75]\teval-rmse:0.24142\n",
      "[76]\teval-rmse:0.24142\n",
      "[77]\teval-rmse:0.24142\n",
      "[78]\teval-rmse:0.24142\n",
      "[79]\teval-rmse:0.24142\n",
      "[80]\teval-rmse:0.24142\n",
      "[81]\teval-rmse:0.24142\n",
      "[82]\teval-rmse:0.24143\n",
      "[83]\teval-rmse:0.24144\n",
      "[84]\teval-rmse:0.24143\n",
      "[85]\teval-rmse:0.24144\n",
      "[86]\teval-rmse:0.24143\n",
      "[87]\teval-rmse:0.24143\n",
      "[88]\teval-rmse:0.24140\n",
      "[89]\teval-rmse:0.24141\n",
      "[90]\teval-rmse:0.24139\n",
      "[91]\teval-rmse:0.24138\n",
      "[92]\teval-rmse:0.24139\n",
      "[93]\teval-rmse:0.24138\n",
      "[94]\teval-rmse:0.24139\n",
      "[95]\teval-rmse:0.24138\n",
      "[96]\teval-rmse:0.24141\n",
      "[97]\teval-rmse:0.24142\n",
      "[98]\teval-rmse:0.24140\n",
      "[99]\teval-rmse:0.24143\n",
      "[100]\teval-rmse:0.24142\n",
      "[101]\teval-rmse:0.24141\n",
      "[102]\teval-rmse:0.24140\n",
      "[103]\teval-rmse:0.24137\n",
      "[104]\teval-rmse:0.24141\n",
      "[105]\teval-rmse:0.24142\n",
      "[106]\teval-rmse:0.24141\n",
      "[107]\teval-rmse:0.24142\n",
      "[108]\teval-rmse:0.24143\n",
      "[109]\teval-rmse:0.24143\n",
      "[110]\teval-rmse:0.24143\n",
      "[111]\teval-rmse:0.24143\n",
      "[112]\teval-rmse:0.24144\n",
      "[113]\teval-rmse:0.24142\n",
      "[114]\teval-rmse:0.24143\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360e1edb6e5b412ab8963ab924f671ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▅▇▁▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.97757</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-sweep-1</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/63ma531g' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/63ma531g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240109_122752-63ma531g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cwlsgl31 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.9055530101651356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.7015615991123816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_value: 0.9741609691592998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_boost_round: 138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.9939909554651328\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240109_123115-cwlsgl31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/cwlsgl31' target=\"_blank\">decent-sweep-2</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/sweeps/z97en3lz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/cwlsgl31' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-xgboost-hyperparameter/runs/cwlsgl31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:0.42917\n",
      "[1]\teval-rmse:0.36035\n",
      "[2]\teval-rmse:0.31551\n",
      "[3]\teval-rmse:0.28614\n",
      "[4]\teval-rmse:0.26559\n",
      "[5]\teval-rmse:0.25325\n",
      "[6]\teval-rmse:0.24349\n",
      "[7]\teval-rmse:0.23702\n",
      "[8]\teval-rmse:0.23183\n",
      "[9]\teval-rmse:0.22838\n",
      "[10]\teval-rmse:0.22632\n",
      "[11]\teval-rmse:0.22423\n",
      "[12]\teval-rmse:0.22308\n",
      "[13]\teval-rmse:0.22153\n",
      "[14]\teval-rmse:0.22037\n",
      "[15]\teval-rmse:0.21967\n",
      "[16]\teval-rmse:0.21919\n",
      "[17]\teval-rmse:0.21864\n",
      "[18]\teval-rmse:0.21832\n",
      "[19]\teval-rmse:0.21799\n",
      "[20]\teval-rmse:0.21796\n",
      "[21]\teval-rmse:0.21765\n",
      "[22]\teval-rmse:0.21745\n",
      "[23]\teval-rmse:0.21746\n",
      "[24]\teval-rmse:0.21714\n",
      "[25]\teval-rmse:0.21692\n",
      "[26]\teval-rmse:0.21706\n",
      "[27]\teval-rmse:0.21692\n",
      "[28]\teval-rmse:0.21681\n",
      "[29]\teval-rmse:0.21671\n",
      "[30]\teval-rmse:0.21655\n",
      "[31]\teval-rmse:0.21634\n",
      "[32]\teval-rmse:0.21622\n",
      "[33]\teval-rmse:0.21613\n",
      "[34]\teval-rmse:0.21603\n",
      "[35]\teval-rmse:0.21607\n",
      "[36]\teval-rmse:0.21591\n",
      "[37]\teval-rmse:0.21586\n",
      "[38]\teval-rmse:0.21583\n",
      "[39]\teval-rmse:0.21588\n",
      "[40]\teval-rmse:0.21595\n",
      "[41]\teval-rmse:0.21588\n",
      "[42]\teval-rmse:0.21590\n",
      "[43]\teval-rmse:0.21585\n",
      "[44]\teval-rmse:0.21580\n",
      "[45]\teval-rmse:0.21582\n",
      "[46]\teval-rmse:0.21568\n",
      "[47]\teval-rmse:0.21562\n",
      "[48]\teval-rmse:0.21550\n",
      "[49]\teval-rmse:0.21545\n",
      "[50]\teval-rmse:0.21535\n",
      "[51]\teval-rmse:0.21526\n",
      "[52]\teval-rmse:0.21528\n",
      "[53]\teval-rmse:0.21531\n",
      "[54]\teval-rmse:0.21544\n",
      "[55]\teval-rmse:0.21541\n",
      "[56]\teval-rmse:0.21536\n",
      "[57]\teval-rmse:0.21541\n",
      "[58]\teval-rmse:0.21543\n",
      "[59]\teval-rmse:0.21549\n",
      "[60]\teval-rmse:0.21551\n",
      "[61]\teval-rmse:0.21547\n",
      "[62]\teval-rmse:0.21545\n",
      "[63]\teval-rmse:0.21542\n",
      "[64]\teval-rmse:0.21540\n",
      "[65]\teval-rmse:0.21536\n",
      "[66]\teval-rmse:0.21531\n",
      "[67]\teval-rmse:0.21524\n",
      "[68]\teval-rmse:0.21519\n",
      "[69]\teval-rmse:0.21520\n",
      "[70]\teval-rmse:0.21519\n",
      "[71]\teval-rmse:0.21517\n",
      "[72]\teval-rmse:0.21516\n",
      "[73]\teval-rmse:0.21516\n",
      "[74]\teval-rmse:0.21510\n",
      "[75]\teval-rmse:0.21511\n",
      "[76]\teval-rmse:0.21512\n",
      "[77]\teval-rmse:0.21506\n",
      "[78]\teval-rmse:0.21499\n",
      "[79]\teval-rmse:0.21496\n",
      "[80]\teval-rmse:0.21496\n",
      "[81]\teval-rmse:0.21494\n",
      "[82]\teval-rmse:0.21492\n",
      "[83]\teval-rmse:0.21494\n",
      "[84]\teval-rmse:0.21494\n",
      "[85]\teval-rmse:0.21493\n",
      "[86]\teval-rmse:0.21491\n",
      "[87]\teval-rmse:0.21489\n",
      "[88]\teval-rmse:0.21491\n",
      "[89]\teval-rmse:0.21487\n",
      "[90]\teval-rmse:0.21487\n",
      "[91]\teval-rmse:0.21485\n",
      "[92]\teval-rmse:0.21488\n",
      "[93]\teval-rmse:0.21488\n",
      "[94]\teval-rmse:0.21489\n",
      "[95]\teval-rmse:0.21486\n",
      "[96]\teval-rmse:0.21486\n",
      "[97]\teval-rmse:0.21486\n",
      "[98]\teval-rmse:0.21482\n",
      "[99]\teval-rmse:0.21480\n",
      "[100]\teval-rmse:0.21480\n",
      "[101]\teval-rmse:0.21478\n",
      "[102]\teval-rmse:0.21481\n",
      "[103]\teval-rmse:0.21482\n",
      "[104]\teval-rmse:0.21481\n",
      "[105]\teval-rmse:0.21481\n",
      "[106]\teval-rmse:0.21480\n",
      "[107]\teval-rmse:0.21480\n",
      "[108]\teval-rmse:0.21480\n",
      "[109]\teval-rmse:0.21480\n",
      "[110]\teval-rmse:0.21478\n",
      "[111]\teval-rmse:0.21476\n",
      "[112]\teval-rmse:0.21477\n",
      "[113]\teval-rmse:0.21474\n",
      "[114]\teval-rmse:0.21471\n",
      "[115]\teval-rmse:0.21473\n",
      "[116]\teval-rmse:0.21470\n",
      "[117]\teval-rmse:0.21470\n",
      "[118]\teval-rmse:0.21468\n",
      "[119]\teval-rmse:0.21470\n",
      "[120]\teval-rmse:0.21469\n",
      "[121]\teval-rmse:0.21471\n",
      "[122]\teval-rmse:0.21471\n",
      "[123]\teval-rmse:0.21471\n",
      "[124]\teval-rmse:0.21471\n",
      "[125]\teval-rmse:0.21469\n",
      "[126]\teval-rmse:0.21470\n",
      "[127]\teval-rmse:0.21468\n",
      "[128]\teval-rmse:0.21469\n",
      "[129]\teval-rmse:0.21470\n",
      "[130]\teval-rmse:0.21469\n",
      "[131]\teval-rmse:0.21469\n",
      "[132]\teval-rmse:0.21467\n",
      "[133]\teval-rmse:0.21466\n",
      "[134]\teval-rmse:0.21464\n",
      "[135]\teval-rmse:0.21465\n",
      "[136]\teval-rmse:0.21464\n",
      "[137]\teval-rmse:0.21465\n",
      "[0]\teval-rmse:0.38390\n",
      "[1]\teval-rmse:0.33142\n",
      "[2]\teval-rmse:0.29286\n",
      "[3]\teval-rmse:0.27170\n",
      "[4]\teval-rmse:0.26157\n",
      "[5]\teval-rmse:0.25508\n",
      "[6]\teval-rmse:0.24923\n",
      "[7]\teval-rmse:0.24667\n",
      "[8]\teval-rmse:0.24352\n",
      "[9]\teval-rmse:0.24241\n",
      "[10]\teval-rmse:0.24081\n",
      "[11]\teval-rmse:0.23955\n",
      "[12]\teval-rmse:0.23860\n",
      "[13]\teval-rmse:0.23790\n",
      "[14]\teval-rmse:0.23784\n",
      "[15]\teval-rmse:0.23736\n",
      "[16]\teval-rmse:0.23736\n",
      "[17]\teval-rmse:0.23707\n",
      "[18]\teval-rmse:0.23682\n",
      "[19]\teval-rmse:0.23627\n",
      "[20]\teval-rmse:0.23624\n",
      "[21]\teval-rmse:0.23587\n",
      "[22]\teval-rmse:0.23554\n",
      "[23]\teval-rmse:0.23534\n",
      "[24]\teval-rmse:0.23588\n",
      "[25]\teval-rmse:0.23575\n",
      "[26]\teval-rmse:0.23559\n",
      "[27]\teval-rmse:0.23560\n",
      "[28]\teval-rmse:0.23556\n",
      "[29]\teval-rmse:0.23544\n",
      "[30]\teval-rmse:0.23550\n",
      "[31]\teval-rmse:0.23540\n",
      "[32]\teval-rmse:0.23541\n",
      "[33]\teval-rmse:0.23534\n",
      "[34]\teval-rmse:0.23507\n",
      "[35]\teval-rmse:0.23501\n",
      "[36]\teval-rmse:0.23501\n",
      "[37]\teval-rmse:0.23498\n",
      "[38]\teval-rmse:0.23508\n",
      "[39]\teval-rmse:0.23514\n",
      "[40]\teval-rmse:0.23506\n",
      "[41]\teval-rmse:0.23498\n",
      "[42]\teval-rmse:0.23499\n",
      "[43]\teval-rmse:0.23492\n",
      "[44]\teval-rmse:0.23478\n",
      "[45]\teval-rmse:0.23478\n",
      "[46]\teval-rmse:0.23477\n",
      "[47]\teval-rmse:0.23475\n",
      "[48]\teval-rmse:0.23494\n",
      "[49]\teval-rmse:0.23500\n",
      "[50]\teval-rmse:0.23534\n",
      "[51]\teval-rmse:0.23529\n",
      "[52]\teval-rmse:0.23522\n",
      "[53]\teval-rmse:0.23510\n",
      "[54]\teval-rmse:0.23514\n",
      "[55]\teval-rmse:0.23505\n",
      "[56]\teval-rmse:0.23501\n",
      "[57]\teval-rmse:0.23506\n",
      "[58]\teval-rmse:0.23507\n",
      "[59]\teval-rmse:0.23500\n",
      "[60]\teval-rmse:0.23503\n",
      "[61]\teval-rmse:0.23502\n",
      "[62]\teval-rmse:0.23498\n",
      "[63]\teval-rmse:0.23497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "## cv split\n",
    "skf = StratifiedGroupKFold(n_splits = 5)\n",
    "skf.get_n_splits(tf_train, y_train, groups =train['prompt_name'])\n",
    "\n",
    "def train_sweep():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        for i, (train_idx, test_idx) in enumerate(skf.split(tf_train, y_train, groups = train['prompt_name'])):\n",
    "            train_X = tf_train[train_idx]\n",
    "            eval_X = tf_train[test_idx];\n",
    "            train_y = y_train[train_idx]\n",
    "            eval_y = y_train[test_idx];\n",
    "            \n",
    "            dtrain = xgb.DMatrix(train_X, label = train_y)\n",
    "            deval = xgb.DMatrix(eval_X, label=eval_y)\n",
    "            params = {\n",
    "                'max_depth': config.max_depth,\n",
    "                'min_child_weight': config.min_child_weight,\n",
    "                'gamma': config.gamma,\n",
    "                'subsample': config.subsample,\n",
    "                'colsample_bytree': config.colsample_bytree,\n",
    "                'lambda': config.lambda_value,\n",
    "                'alpha': config.alpha\n",
    "            }\n",
    "            model = xgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                evals = [(deval, 'eval')],\n",
    "                num_boost_round = config.num_boost_round,\n",
    "                early_stopping_rounds=100\n",
    "            )\n",
    "            #model = lightgbm.train(params, train_data, valid_sets = [eval_data])\n",
    "            \n",
    "            eval_preds = model.predict(deval)\n",
    "            del dtrain,deval\n",
    "            gc.collect()\n",
    "            \n",
    "            fpr, tpr, thresholds = metrics.roc_curve(eval_y, eval_preds, pos_label = 1)\n",
    "            eval_auc = metrics.auc(fpr, tpr)\n",
    "            wandb.log({\n",
    "                'validatoin_auc': eval_auc\n",
    "            });\n",
    "wandb.agent(sweep_id, function = train_sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b63630",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2585fb",
   "metadata": {},
   "source": [
    "### Best parameters\n",
    "\n",
    "* colsample_bynode = 0.9669\n",
    "* colsample_bytree = 0.9645\n",
    "* lambda_l1 = 0.7217\n",
    "* lambda_l2 = 3.207\n",
    "* learning_rate = 0.09574\n",
    "* max_bin = 184\n",
    "* max_depth = 62\n",
    "* min_data_in_leaf = 111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089daac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
