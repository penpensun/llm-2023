{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db58bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ec8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n",
      "3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeng_sun\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import lightgbm\n",
    "\n",
    "print(sklearn.__version__)\n",
    "print(lightgbm.__version__)\n",
    "\n",
    "## log into wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8746d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/test_essays.csv')\n",
    "sub = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/sample_submission.csv')\n",
    "org_train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/train_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774cc0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/daigt/train_v2_drcat_02.csv', sep=',')\n",
    "display(train.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b3f5c",
   "metadata": {},
   "source": [
    "#### Read and append the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950181df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18894, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_gen_data = pd.read_parquet('/home/peng_sun2/s3shared/kaggle/llm-2023/external_data/gen_data_21122023.parquet')\n",
    "display(train_gen_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8ff17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates(subset = ['text'])\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "\n",
    "### append the generated data\n",
    "# train = pd.concat([train, train_gen_data], axis = 0).reset_index(drop = True)\n",
    "# display(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96d7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train.loc[train['label'] ==0, :].reset_index(drop = True)\n",
    "train_1 = train.loc[train['label'] ==1, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ce322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27371, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff76121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17497, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a54b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_length = min(len(train_0), len(train_1))\n",
    "# min_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4035fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_train= pd.DataFrame()\n",
    "# for i in tqdm(range(min_length), total = min_length):\n",
    "#     sorted_train = pd.concat([sorted_train, pd.DataFrame(train_0.iloc[i,:]).T], axis = 0)\n",
    "#     sorted_train = pd.concat([sorted_train, pd.DataFrame(train_1.iloc[i,:]).T], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856d300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(train_0) > min_length:\n",
    "#     sorted_train = pd.concat([sorted_train, train_0.iloc[min_length:, :]], axis = 0)\n",
    "# elif len(train_1) > min_length:\n",
    "#     sorted_train = pd.concat([sorted_train, train_1.iloc[min_length:, :]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aadc4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def sort_train(train):\n",
    "    train_0 = train.loc[train['label'] ==0, :].reset_index(drop = True)\n",
    "    train_1 = train.loc[train['label'] ==1, :].reset_index(drop = True)\n",
    "    \n",
    "    min_length = min(len(train_0), len(train_1))\n",
    "    \n",
    "    sorted_train= pd.DataFrame()\n",
    "    for i in tqdm(range(min_length), total = min_length):\n",
    "        sorted_train = pd.concat([sorted_train, pd.DataFrame(train_0.iloc[i,:]).T], axis = 0)\n",
    "        sorted_train = pd.concat([sorted_train, pd.DataFrame(train_1.iloc[i,:]).T], axis = 0)\n",
    "    \n",
    "    if len(train_0) > min_length:\n",
    "        sorted_train = pd.concat([sorted_train, train_0.iloc[min_length:, :]], axis = 0)\n",
    "    elif len(train_1) > min_length:\n",
    "        sorted_train = pd.concat([sorted_train, train_1.iloc[min_length:, :]], axis = 0)\n",
    "        \n",
    "    del train_0, train_1, train\n",
    "    sorted_train['label'] = sorted_train['label'].astype(np.int32)\n",
    "    return sorted_train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b1faa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cell phone use should not be legal while drivi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phones and Driving\\n\\nDriving is a good way to...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PHONES AND DRIVING\\n\\nIn this world in which w...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>People are debating whether if drivers should ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texting and driving\\n\\nOver half of drivers in...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Phones\\n\\nModern humans today are always on th...      0   \n",
       "1  This essay will explain if drivers should or s...      0   \n",
       "2  Driving while the use of cellular devices\\n\\nT...      0   \n",
       "3  Phones & Driving\\n\\nDrivers should not be able...      0   \n",
       "4  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n",
       "5  Cell phone use should not be legal while drivi...      0   \n",
       "6  Phones and Driving\\n\\nDriving is a good way to...      0   \n",
       "7  PHONES AND DRIVING\\n\\nIn this world in which w...      0   \n",
       "8  People are debating whether if drivers should ...      0   \n",
       "9  Texting and driving\\n\\nOver half of drivers in...      0   \n",
       "\n",
       "          prompt_name           source  RDizzl3_seven  \n",
       "0  Phones and driving  persuade_corpus          False  \n",
       "1  Phones and driving  persuade_corpus          False  \n",
       "2  Phones and driving  persuade_corpus          False  \n",
       "3  Phones and driving  persuade_corpus          False  \n",
       "4  Phones and driving  persuade_corpus          False  \n",
       "5  Phones and driving  persuade_corpus          False  \n",
       "6  Phones and driving  persuade_corpus          False  \n",
       "7  Phones and driving  persuade_corpus          False  \n",
       "8  Phones and driving  persuade_corpus          False  \n",
       "9  Phones and driving  persuade_corpus          False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train.shape)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce464667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17497/17497 [00:46<00:00, 372.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train = sort_train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20f4501c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In recent years, technology has had a profoun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>mistral7binstruct_v2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I strongly believe that meditation and mindful...</td>\n",
       "      <td>1</td>\n",
       "      <td>Distance learning</td>\n",
       "      <td>llama_70b_v1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One way school administrators can attempt to c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cell phones at school</td>\n",
       "      <td>chat_gpt_moth</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>While summer is meant as a break from the regu...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer projects</td>\n",
       "      <td>darragh_claude_v7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The use of Facial Action Coding System (FACS) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facial action coding system</td>\n",
       "      <td>darragh_claude_v6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Phones\\n\\nModern humans today are always on th...      0   \n",
       "1   In recent years, technology has had a profoun...      1   \n",
       "2  This essay will explain if drivers should or s...      0   \n",
       "3  I strongly believe that meditation and mindful...      1   \n",
       "4  Driving while the use of cellular devices\\n\\nT...      0   \n",
       "5  One way school administrators can attempt to c...      1   \n",
       "6  Phones & Driving\\n\\nDrivers should not be able...      0   \n",
       "7  While summer is meant as a break from the regu...      1   \n",
       "8  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n",
       "9  The use of Facial Action Coding System (FACS) ...      1   \n",
       "\n",
       "                   prompt_name                source RDizzl3_seven  \n",
       "0           Phones and driving       persuade_corpus         False  \n",
       "1              Car-free cities  mistral7binstruct_v2          True  \n",
       "2           Phones and driving       persuade_corpus         False  \n",
       "3            Distance learning          llama_70b_v1         False  \n",
       "4           Phones and driving       persuade_corpus         False  \n",
       "5        Cell phones at school         chat_gpt_moth         False  \n",
       "6           Phones and driving       persuade_corpus         False  \n",
       "7              Summer projects     darragh_claude_v7         False  \n",
       "8           Phones and driving       persuade_corpus         False  \n",
       "9  Facial action coding system     darragh_claude_v6          True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train.shape)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f647664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWERCASE = False\n",
    "VOCAB_SIZE = 30522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9b4831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create byte-pair encoding tokenizer\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token='[UNK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb8ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding normalization and pre_tokenizer\n",
    "raw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()]+ [normalizers.Lowercase()] if LOWERCASE else [])\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f33614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding special tokens and creating trainer instance\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size = VOCAB_SIZE, special_tokens = special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08980728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/pyarrow/pandas_compat.py:358: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3875.24it/s]\n",
      "100%|██████████| 44868/44868 [02:16<00:00, 328.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating huggingface dataset object\n",
    "dataset = Dataset.from_pandas(test[['text']])\n",
    "def train_corp_iter():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i:i+1000]['text']\n",
    "raw_tokenizer.train_from_iterator(train_corp_iter(), trainer = trainer)\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "tokenized_texts_test = []\n",
    "for text in tqdm(test['text'].tolist()):\n",
    "    tokenized_texts_test.append(tokenizer.tokenize(text))\n",
    "\n",
    "tokenized_texts_train = []\n",
    "\n",
    "for text in tqdm(train['text'].tolist()):\n",
    "    tokenized_texts_train.append(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f7ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ĠBbb', 'Ġccc', 'Ġddd', '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93001dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c63bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ĠAaa Ġbbb Ġccc': 0, 'Ġbbb Ġccc .': 6, 'ĠAaa Ġbbb Ġccc .': 1, 'ĠBbb Ġccc Ġddd': 2, 'Ġccc Ġddd .': 7, 'ĠBbb Ġccc Ġddd .': 3, 'ĠCCC Ġddd Ġeee': 4, 'Ġddd Ġeee .': 8, 'ĠCCC Ġddd Ġeee .': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (3, 5), lowercase=False, sublinear_tf = True, analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None,\n",
    "                            strip_accents = 'unicode',\n",
    "                            dtype = np.float32)\n",
    "vectorizer.fit(tokenized_texts_test)\n",
    "\n",
    "# Getting vocab\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, \n",
    "                             #vocabulary=vocab,\n",
    "                            analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None, strip_accents='unicode',\n",
    "                            dtype = np.float32\n",
    "                            )\n",
    "\n",
    "tf_train = vectorizer.fit_transform(tokenized_texts_train)\n",
    "tf_test = vectorizer.transform(tokenized_texts_test)\n",
    "## get the vocabulary of the training dataset\n",
    "train_vocab = vectorizer.vocabulary_\n",
    "\n",
    "del vectorizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7a56d",
   "metadata": {},
   "source": [
    "### Convert the type from numpy.float64 to numpy.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff0482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# ## convert data for tf_train\n",
    "# data  = tf_train.data.astype(np.float16)\n",
    "# indices = tf_train.indices\n",
    "# indptr = tf_train.indptr\n",
    "# tf_train = csr_matrix((data, indices, indptr), shape = tf_train.shape)\n",
    "\n",
    "\n",
    "# ## convert data for tf_test\n",
    "# data = tf_test.data.astype(np.float16)\n",
    "# indices = tf_test.indices\n",
    "# indptr = tf_test.indptr\n",
    "# tf_test = csr_matrix((data, indices, indptr), shape = tf_test.shape)\n",
    "\n",
    "# del data, indices, indptr\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0209d0a",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c0db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### save train_vocab\n",
    "# import joblib\n",
    "# model_path = '/home/peng_sun2/s3shared/kaggle/llm-2023/baseline1/'\n",
    "# joblib.dump(train_vocab, f'{model_path}vocab_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3c74dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ar59lm66\n",
      "Sweep URL: https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Check if it's in scoring stage\n",
    "# if len(test.text.values) <= 5:\n",
    "#     # if not, just sample submission\n",
    "#     sub.to_csv('submission.csv', index=False)\n",
    "# else:\n",
    "# otherwise, run fitting process\n",
    "\n",
    "p6={\n",
    "    'n_iter': 1500,\n",
    "    'verbose': -1,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05073909898961407, \n",
    "    'colsample_bytree': 0.726023996436955, \n",
    "    'colsample_bynode': 0.5803681307354022, \n",
    "    'lambda_l1': 8.562963348932286, \n",
    "    'lambda_l2': 4.893256185259296, \n",
    "    'min_data_in_leaf': 115, \n",
    "    'max_depth': 123, \n",
    "    'max_bin': 250,\n",
    "    'device': 'gpu'\n",
    "}\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {'name': 'validatoin_auc', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'n_iter': {'min': 500, 'max': 1500},\n",
    "        'learning_rate': {'min': 0.01, 'max': 0.1},\n",
    "        'colsample_bytree': {'min': 0.5, 'max': 1.0},\n",
    "        'colsample_bynode': {'min': 0.5, 'max': 1.0},\n",
    "        'lambda_l1': {'min': 0.0, 'max': 10.0},\n",
    "        'lambda_l2': {'min': 0.0, 'max': 10.0},\n",
    "        'min_data_in_leaf': {'min': 50, 'max': 150},\n",
    "        'max_depth': {'min': 10, 'max': 200},\n",
    "        'max_bin': {'min': 100, 'max': 300}\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"llm-2023-lightgbm-hyperparameter-fixed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5954df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_range_into_parts(start, end, num_parts):\n",
    "    splits = np.linspace(start, end, num_parts + 1)\n",
    "    ranges = [(int(np.floor(splits[i])), int(np.ceil(splits[i + 1]))) for i in range(num_parts)]\n",
    "    return np.array(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d2730d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_train_catboost(tf_train, y_train, cat, num_parts):\n",
    "    split_ranges = split_range_into_parts(0, tf_train.shape[0], num_parts);\n",
    "    #print(split_ranges)\n",
    "    \n",
    "    ## incrementally train catboost\n",
    "    for i, (start, end) in enumerate(split_ranges):\n",
    "        print('start, end ', start, ' ', end)\n",
    "        train_X_split = tf_train[start:end, :]\n",
    "        train_y_split = y_train[start:end]\n",
    "        \n",
    "        #print(train_X_split.shape, train_y_split.shape)\n",
    "        if i ==0:\n",
    "            cat.fit(train_X_split, train_y_split)\n",
    "        else: \n",
    "            cat.fit(train_X_split, train_y_split, init_model = cat)\n",
    "        print(f'part {i} is finished ...')\n",
    "    return cat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7941cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59c317d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 65w9tct1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.5444998482851979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.777343321763381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 1.4116505840290638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 1.196319732891905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05520324725970579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 1103\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_124148-65w9tct1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/65w9tct1' target=\"_blank\">icy-sweep-1</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/65w9tct1' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/65w9tct1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=1.196319732891905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.196319732891905\n",
      "[LightGBM] [Warning] num_iterations is set=1103, n_iter=1103 will be ignored. Current value: num_iterations=1103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4116505840290638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4116505840290638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=1.196319732891905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.196319732891905\n",
      "[LightGBM] [Warning] num_iterations is set=1103, n_iter=1103 will be ignored. Current value: num_iterations=1103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4116505840290638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4116505840290638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=1.196319732891905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.196319732891905\n",
      "[LightGBM] [Warning] num_iterations is set=1103, n_iter=1103 will be ignored. Current value: num_iterations=1103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4116505840290638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4116505840290638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=1.196319732891905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.196319732891905\n",
      "[LightGBM] [Warning] num_iterations is set=1103, n_iter=1103 will be ignored. Current value: num_iterations=1103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4116505840290638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4116505840290638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=1.196319732891905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.196319732891905\n",
      "[LightGBM] [Warning] num_iterations is set=1103, n_iter=1103 will be ignored. Current value: num_iterations=1103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4116505840290638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4116505840290638\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8052d0174815474197d847a7551dd2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.99563</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-sweep-1</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/65w9tct1' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/65w9tct1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240103_124148-65w9tct1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jsdacd2x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.8491833950010457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.8075508639834386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 5.601468958410967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 3.3682594140375723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03438330255523524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 71\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 1455\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_130242-jsdacd2x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/jsdacd2x' target=\"_blank\">charmed-sweep-2</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/jsdacd2x' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/jsdacd2x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=3.3682594140375723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3682594140375723\n",
      "[LightGBM] [Warning] num_iterations is set=1455, n_iter=1455 will be ignored. Current value: num_iterations=1455\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.601468958410967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.601468958410967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=3.3682594140375723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3682594140375723\n",
      "[LightGBM] [Warning] num_iterations is set=1455, n_iter=1455 will be ignored. Current value: num_iterations=1455\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.601468958410967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.601468958410967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=3.3682594140375723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3682594140375723\n",
      "[LightGBM] [Warning] num_iterations is set=1455, n_iter=1455 will be ignored. Current value: num_iterations=1455\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.601468958410967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.601468958410967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=3.3682594140375723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3682594140375723\n",
      "[LightGBM] [Warning] num_iterations is set=1455, n_iter=1455 will be ignored. Current value: num_iterations=1455\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.601468958410967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.601468958410967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=3.3682594140375723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3682594140375723\n",
      "[LightGBM] [Warning] num_iterations is set=1455, n_iter=1455 will be ignored. Current value: num_iterations=1455\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.601468958410967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.601468958410967\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3986cbc8450644058e122f6287f5941f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.174939…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.99499</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-sweep-2</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/jsdacd2x' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/jsdacd2x</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240103_130242-jsdacd2x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l6c3gnkv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.6323394140145904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.9584094566157332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 3.894711499136416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 7.856718332506171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.019948507105120528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 58\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 1338\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_132302-l6c3gnkv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/l6c3gnkv' target=\"_blank\">sparkling-sweep-3</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/l6c3gnkv' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/l6c3gnkv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.856718332506171, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.856718332506171\n",
      "[LightGBM] [Warning] num_iterations is set=1338, n_iter=1338 will be ignored. Current value: num_iterations=1338\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.894711499136416, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.894711499136416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.856718332506171, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.856718332506171\n",
      "[LightGBM] [Warning] num_iterations is set=1338, n_iter=1338 will be ignored. Current value: num_iterations=1338\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.894711499136416, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.894711499136416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.856718332506171, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.856718332506171\n",
      "[LightGBM] [Warning] num_iterations is set=1338, n_iter=1338 will be ignored. Current value: num_iterations=1338\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.894711499136416, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.894711499136416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.856718332506171, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.856718332506171\n",
      "[LightGBM] [Warning] num_iterations is set=1338, n_iter=1338 will be ignored. Current value: num_iterations=1338\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.894711499136416, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.894711499136416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.856718332506171, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.856718332506171\n",
      "[LightGBM] [Warning] num_iterations is set=1338, n_iter=1338 will be ignored. Current value: num_iterations=1338\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.894711499136416, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.894711499136416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.99537</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-sweep-3</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/l6c3gnkv' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/l6c3gnkv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240103_132302-l6c3gnkv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cilwnykj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.9015616993708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.5896172884289925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 9.632926603654491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 7.392026743983925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0748430738156277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 808\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_141156-cilwnykj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/cilwnykj' target=\"_blank\">stilted-sweep-4</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/cilwnykj' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/cilwnykj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.392026743983925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.392026743983925\n",
      "[LightGBM] [Warning] num_iterations is set=808, n_iter=808 will be ignored. Current value: num_iterations=808\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.632926603654491, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.632926603654491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.392026743983925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.392026743983925\n",
      "[LightGBM] [Warning] num_iterations is set=808, n_iter=808 will be ignored. Current value: num_iterations=808\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.632926603654491, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.632926603654491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.392026743983925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.392026743983925\n",
      "[LightGBM] [Warning] num_iterations is set=808, n_iter=808 will be ignored. Current value: num_iterations=808\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.632926603654491, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.632926603654491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.392026743983925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.392026743983925\n",
      "[LightGBM] [Warning] num_iterations is set=808, n_iter=808 will be ignored. Current value: num_iterations=808\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.632926603654491, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.632926603654491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.392026743983925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.392026743983925\n",
      "[LightGBM] [Warning] num_iterations is set=808, n_iter=808 will be ignored. Current value: num_iterations=808\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.632926603654491, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.632926603654491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a81e162b3846bdacf57840d30b3a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.99476</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-sweep-4</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/cilwnykj' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/cilwnykj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240103_141156-cilwnykj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5olnwasa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.660911836718977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.5386705181410137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 2.958016762475072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 9.066868283622044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08174538786969733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 76\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 1033\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_142234-5olnwasa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/5olnwasa' target=\"_blank\">likely-sweep-5</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/5olnwasa' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/5olnwasa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=9.066868283622044, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.066868283622044\n",
      "[LightGBM] [Warning] num_iterations is set=1033, n_iter=1033 will be ignored. Current value: num_iterations=1033\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.958016762475072, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.958016762475072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=9.066868283622044, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.066868283622044\n",
      "[LightGBM] [Warning] num_iterations is set=1033, n_iter=1033 will be ignored. Current value: num_iterations=1033\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.958016762475072, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.958016762475072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=9.066868283622044, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.066868283622044\n",
      "[LightGBM] [Warning] num_iterations is set=1033, n_iter=1033 will be ignored. Current value: num_iterations=1033\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.958016762475072, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.958016762475072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=9.066868283622044, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.066868283622044\n",
      "[LightGBM] [Warning] num_iterations is set=1033, n_iter=1033 will be ignored. Current value: num_iterations=1033\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.958016762475072, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.958016762475072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=9.066868283622044, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.066868283622044\n",
      "[LightGBM] [Warning] num_iterations is set=1033, n_iter=1033 will be ignored. Current value: num_iterations=1033\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.958016762475072, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.958016762475072\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.99513</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-5</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/5olnwasa' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/5olnwasa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240103_142234-5olnwasa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q2sim921 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.9625552674204478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.6947653290955336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 5.4163669910296095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 4.213934716239562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09851272932465086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 1376\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_143437-q2sim921</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/q2sim921' target=\"_blank\">fluent-sweep-6</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/q2sim921' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/q2sim921</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=4.213934716239562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.213934716239562\n",
      "[LightGBM] [Warning] num_iterations is set=1376, n_iter=1376 will be ignored. Current value: num_iterations=1376\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=109, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.4163669910296095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.4163669910296095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=4.213934716239562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.213934716239562\n",
      "[LightGBM] [Warning] num_iterations is set=1376, n_iter=1376 will be ignored. Current value: num_iterations=1376\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=109, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.4163669910296095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.4163669910296095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=4.213934716239562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.213934716239562\n",
      "[LightGBM] [Warning] num_iterations is set=1376, n_iter=1376 will be ignored. Current value: num_iterations=1376\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=109, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.4163669910296095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.4163669910296095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=4.213934716239562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.213934716239562\n",
      "[LightGBM] [Warning] num_iterations is set=1376, n_iter=1376 will be ignored. Current value: num_iterations=1376\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=109, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.4163669910296095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.4163669910296095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=4.213934716239562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.213934716239562\n",
      "[LightGBM] [Warning] num_iterations is set=1376, n_iter=1376 will be ignored. Current value: num_iterations=1376\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=109, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.4163669910296095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.4163669910296095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.99485</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fluent-sweep-6</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/q2sim921' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/q2sim921</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240103_143437-q2sim921/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ofp2wufi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.6263559939585119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.8303376739858693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 8.511936901581581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 2.9155878730741303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.010393645676901422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 85\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 819\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_144430-ofp2wufi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/ofp2wufi' target=\"_blank\">happy-sweep-7</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/ofp2wufi' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/ofp2wufi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=2.9155878730741303, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9155878730741303\n",
      "[LightGBM] [Warning] num_iterations is set=819, n_iter=819 will be ignored. Current value: num_iterations=819\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=112, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=112\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.511936901581581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.511936901581581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=2.9155878730741303, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9155878730741303\n",
      "[LightGBM] [Warning] num_iterations is set=819, n_iter=819 will be ignored. Current value: num_iterations=819\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=112, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=112\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.511936901581581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.511936901581581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=2.9155878730741303, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9155878730741303\n",
      "[LightGBM] [Warning] num_iterations is set=819, n_iter=819 will be ignored. Current value: num_iterations=819\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=112, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=112\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.511936901581581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.511936901581581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=2.9155878730741303, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9155878730741303\n",
      "[LightGBM] [Warning] num_iterations is set=819, n_iter=819 will be ignored. Current value: num_iterations=819\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=112, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=112\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.511936901581581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.511936901581581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=2.9155878730741303, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9155878730741303\n",
      "[LightGBM] [Warning] num_iterations is set=819, n_iter=819 will be ignored. Current value: num_iterations=819\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=112, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=112\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.511936901581581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.511936901581581\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validatoin_auc</td><td>0.99335</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-7</strong> at: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/ofp2wufi' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/ofp2wufi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240103_144430-ofp2wufi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j0g8tg43 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bynode: 0.9209134585407984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 0.6793425944457387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 0.362892679276644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 7.314821068229827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05914851581564762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_bin: 274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_iter: 885\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peng_sun2/workspace/llm-2023/wandb/run-20240103_150744-j0g8tg43</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/j0g8tg43' target=\"_blank\">bumbling-sweep-8</a></strong> to <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/sweeps/ar59lm66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/j0g8tg43' target=\"_blank\">https://wandb.ai/peng_sun/llm-2023-lightgbm-hyperparameter-fixed/runs/j0g8tg43</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.314821068229827, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.314821068229827\n",
      "[LightGBM] [Warning] num_iterations is set=885, n_iter=885 will be ignored. Current value: num_iterations=885\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.362892679276644, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.362892679276644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.314821068229827, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.314821068229827\n",
      "[LightGBM] [Warning] num_iterations is set=885, n_iter=885 will be ignored. Current value: num_iterations=885\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.362892679276644, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.362892679276644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.314821068229827, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.314821068229827\n",
      "[LightGBM] [Warning] num_iterations is set=885, n_iter=885 will be ignored. Current value: num_iterations=885\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.362892679276644, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.362892679276644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=7.314821068229827, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.314821068229827\n",
      "[LightGBM] [Warning] num_iterations is set=885, n_iter=885 will be ignored. Current value: num_iterations=885\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.362892679276644, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.362892679276644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "## cv split\n",
    "skf = StratifiedGroupKFold(n_splits = 5)\n",
    "skf.get_n_splits(tf_train, y_train, groups =train['prompt_name'])\n",
    "\n",
    "def train_sweep():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        for i, (train_idx, test_idx) in enumerate(skf.split(tf_train, y_train, groups = train['prompt_name'])):\n",
    "            train_X = tf_train[train_idx]\n",
    "            eval_X = tf_train[test_idx];\n",
    "            train_y = y_train[train_idx]\n",
    "            eval_y = y_train[test_idx];\n",
    "            \n",
    "            params = {\n",
    "                'n_iter': config.n_iter,\n",
    "                'verbose': -1,\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'learning_rate': config.learning_rate,\n",
    "                'colsample_bytree': config.colsample_bytree,\n",
    "                'colsample_bynode': config.colsample_bynode,\n",
    "                'lambda_l1': config.lambda_l1,\n",
    "                'lambda_l2': config.lambda_l2,\n",
    "                'min_data_in_leaf': config.min_data_in_leaf,\n",
    "                'max_depth': config.max_depth,\n",
    "                'max_bin': config.max_bin\n",
    "            }\n",
    "            \n",
    "            model = LGBMClassifier(**params)\n",
    "            #model = lightgbm.train(params, train_data, valid_sets = [eval_data])\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            eval_preds = model.predict_proba(eval_X)[:, 1]\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(eval_y, eval_preds, pos_label = 1)\n",
    "            eval_auc = metrics.auc(fpr, tpr)\n",
    "            wandb.log({\n",
    "                'validatoin_auc': eval_auc\n",
    "            });\n",
    "wandb.agent(sweep_id, function = train_sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2b63630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_22995/2988667965.py\", line 41, in train_sweep\n",
      "    wandb.log({\n",
      "  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2585fb",
   "metadata": {},
   "source": [
    "### Best parameters\n",
    "\n",
    "* colsample_bynode = 0.9669\n",
    "* colsample_bytree = 0.9645\n",
    "* lambda_l1 = 0.7217\n",
    "* lambda_l2 = 3.207\n",
    "* learning_rate = 0.09574\n",
    "* max_bin = 184\n",
    "* max_depth = 62\n",
    "* min_data_in_leaf = 111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089daac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
