{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3947,
     "status": "ok",
     "timestamp": 1705228724679,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "qa7m6_h7BGqS",
    "outputId": "43321d7d-d10f-479c-ba16-09e24d8350e6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 10043,
     "status": "ok",
     "timestamp": 1705228734720,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "o44kXeFSBNTg",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers[sentencepiece]\n",
    "!pip install -q colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1705228734721,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "DAymYtbTBVx4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/LLM - Detect AI Generated Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3348,
     "status": "ok",
     "timestamp": 1705228738059,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "e3F2EvDmBC6y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1705228740835,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "BP3agx_rBC62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 2023,\n",
    "          \"epochs\": 3,\n",
    "          #\"model_name\": \"microsoft/deberta-v3-base\",\n",
    "          \"model_name\": \"/root/autodl-tmp/deberta-v3-large\",\n",
    "          #\"train_batch_size\": 80,\n",
    "          \"train_batch_size\": 16, # Peng's code\n",
    "          \"valid_batch_size\": 16,\n",
    "          #\"max_length\": 128,\n",
    "          \"max_length\": 512,\n",
    "          \"learning_rate\": 5e-5,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-6,\n",
    "          \"n_fold\": 5,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 1,\n",
    "          \"margin\": 0.5,\n",
    "          \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          }\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "CONFIG['group'] = f'Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1705228740835,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "GewPFVMyBC62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 1588,
     "status": "ok",
     "timestamp": 1705228742420,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "ft5wVEMpBC63",
    "outputId": "7a7e86b3-f016-49ae-a301-d8563f0106e4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ai</th>\n",
       "      <th>human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>As a grade 10 student, I strongly argue agains...</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>While cell phones have become ubiquitous in mo...</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>Social media platforms have taken over the wor...</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>I think there should be stronger privacy prote...</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>Drivers should not be able to use cell phones ...</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                title                                                 ai  \\\n",
       "0  Phones and driving  As a grade 10 student, I strongly argue agains...   \n",
       "1  Phones and driving  While cell phones have become ubiquitous in mo...   \n",
       "2  Phones and driving  Social media platforms have taken over the wor...   \n",
       "3  Phones and driving  I think there should be stronger privacy prote...   \n",
       "4  Phones and driving  Drivers should not be able to use cell phones ...   \n",
       "\n",
       "                                               human  \n",
       "0  Phones\\n\\nModern humans today are always on th...  \n",
       "1  Phones\\n\\nModern humans today are always on th...  \n",
       "2  Phones\\n\\nModern humans today are always on th...  \n",
       "3  Phones\\n\\nModern humans today are always on th...  \n",
       "4  Phones\\n\\nModern humans today are always on th...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"./data/pair_wise_train_ds.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1705228742420,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "ngjf9jRhBC63",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairWiseDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        #self.prompt = df['prompt'].values\n",
    "        self.ai = df['ai'].values\n",
    "        self.human = df['human'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #prompt = self.prompt[index]\n",
    "        ai_text = self.ai[index]\n",
    "        human_text = self.human[index]\n",
    "        inputs_ai = self.tokenizer(\n",
    "                                #prompt,\n",
    "                                ai_text,\n",
    "                                truncation=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        inputs_human = self.tokenizer(\n",
    "                                #prompt,\n",
    "                                human_text,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        target = 1\n",
    "\n",
    "        ai_input_ids = inputs_ai['input_ids']\n",
    "        ai_attention_mask = inputs_ai['attention_mask']\n",
    "\n",
    "        human_input_ids = inputs_human['input_ids']\n",
    "        huamn_attention_mask = inputs_human['attention_mask']\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ai_input_ids': torch.tensor(ai_input_ids, dtype=torch.long),\n",
    "            'ai_attention_mask': torch.tensor(ai_attention_mask, dtype=torch.long),\n",
    "            'human_input_ids': torch.tensor(human_input_ids, dtype=torch.long),\n",
    "            'huamn_attention_mask': torch.tensor(huamn_attention_mask, dtype=torch.long),\n",
    "            'target': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1705228742420,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "kxA8gMb1BC63",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        #self.prompt = df['prompt'].values\n",
    "        self.text = df['text'].values\n",
    "        self.target = df['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #prompt = self.prompt[index]\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer(\n",
    "                                #prompt,\n",
    "                                text,\n",
    "                                truncation=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length')\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        target = self.target[index]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'target': torch.tensor(target, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1705228742421,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "8334rCKQBC64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AiDectModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(AiDectModel, self).__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "        # out = self.drop(out[1])\n",
    "        # outputs = self.fc(out)\n",
    "        return out.logits.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1705228742421,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "oPNviEzVBC64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "\n",
    "    ce_pos_label = torch.as_tensor([1.] * CONFIG['train_batch_size']).to(CONFIG['device'])\n",
    "    ce_neg_label = torch.as_tensor([0.] * CONFIG['train_batch_size']).to(CONFIG['device'])\n",
    "    ce_loss = nn.BCEWithLogitsLoss()(outputs1, ce_pos_label) +  nn.BCEWithLogitsLoss()(outputs2, ce_neg_label)\n",
    "    rank_loss = nn.MarginRankingLoss(margin=CONFIG['margin'])(outputs1, outputs2, targets)\n",
    "    return 0.5 * ce_loss + rank_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1705228742421,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "JIwnu-19BC65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        ai_input_ids = data['ai_input_ids'].to(device, dtype = torch.long)\n",
    "        ai_attention_mask = data['ai_attention_mask'].to(device, dtype = torch.long)\n",
    "        human_input_ids = data['human_input_ids'].to(device, dtype = torch.long)\n",
    "        huamn_attention_mask = data['huamn_attention_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        #Peng's code test\n",
    "        print('ai_input_ids: ', ai_input_ids)\n",
    "        \n",
    "        batch_size = ai_input_ids.size(0)\n",
    "\n",
    "        ai_outputs = model(ai_input_ids, ai_attention_mask)\n",
    "        #Peng's code test\n",
    "        print('ai_outputs: ', ai_outputs)\n",
    "        human_outputs = model(human_input_ids, huamn_attention_mask)\n",
    "        loss = criterion(ai_outputs, human_outputs, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1705228742421,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "ZGXCnNoqBC65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    preds = []\n",
    "    gts = []\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        input_ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        attention_mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target']\n",
    "        \n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        preds.append(outputs.sigmoid().cpu().numpy())\n",
    "        gts.append(targets.numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    gts = np.concatenate(gts)\n",
    "\n",
    "    auc_score = roc_auc_score(gts, preds)\n",
    "    gc.collect()\n",
    "\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1705228742421,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "Y3hrOomsBC65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    # To automatically log gradients\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_score = -1\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "        print('before train_one_epoch:');\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler,\n",
    "                                            dataloader=train_loader,\n",
    "                                            device=CONFIG['device'], epoch=epoch)\n",
    "        print('after train_one_epoch:')\n",
    "        train_epoch_loss = 1\n",
    "        val_epoch_score = valid_one_epoch(model, valid_loader, device=CONFIG['device'],\n",
    "                                         epoch=epoch)\n",
    "\n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid score'].append(val_epoch_score)\n",
    "\n",
    "\n",
    "        # deep copy the model\n",
    "        if val_epoch_score > best_epoch_score:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_score} ---> {val_epoch_score})\")\n",
    "            best_epoch_score = val_epoch_score\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Score: {:.4f}\".format(best_epoch_score))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1705228742421,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "jURCypp-BC66",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_loaders():\n",
    "    df_train = df[df.title != 'Car-free cities'].reset_index(drop=True)\n",
    "    df_valid = df[df.title == 'Car-free cities'].reset_index(drop=True)\n",
    "    #val_prompt = df_valid.prompt.unique()[0]\n",
    "    df_valid_pos = pd.DataFrame({\n",
    "                                'text' : df_valid.ai.unique().tolist(),\n",
    "    })\n",
    "    df_valid_pos['label'] = 1\n",
    "    df_valid_neg = pd.DataFrame({\n",
    "                                'text' : df_valid.human.unique().tolist(),\n",
    "    })\n",
    "    df_valid_neg['label'] = 0\n",
    "    df_valid = pd.concat([df_valid_pos, df_valid_neg])\n",
    "    #df_valid['prompt'] = val_prompt\n",
    "    train_dataset = PairWiseDataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'],\n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "\n",
    "    valid_dataset = TestDataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'],\n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1705228742422,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "ieeFxICbBC66",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'],\n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'],\n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YR1zkUUGBC66"
   },
   "source": [
    "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "executionInfo": {
     "elapsed": 7951425,
     "status": "error",
     "timestamp": 1705236693837,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "m2toqbX2BC67",
    "outputId": "8f091cc1-d17e-42f1-941a-1a684c08392b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m====== Fold: 0 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/deberta-v3-large and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: Tesla V100-PCIE-32GB\n",
      "\n",
      "before train_one_epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15440 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_input_ids:  tensor([[    1,   463,   266,  ...,     0,     0,     0],\n",
      "        [    1, 10147,  7455,  ...,     0,     0,     0],\n",
      "        [    1, 10147, 11311,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  5388,   261,  ...,     0,     0,     0],\n",
      "        [    1,   279,   380,  ...,     0,     0,     0],\n",
      "        [    1, 10147,  7455,  ...,     0,     0,     0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
    "\n",
    "\n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders()\n",
    "\n",
    "    model = AiDectModel(CONFIG['model_name'])\n",
    "    \n",
    "    ##multiple GPUs, peng's code\n",
    "    #device_ids = [1, 2]\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    # commented out by Peng\n",
    "    #model.to(CONFIG['device'])\n",
    "\n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "\n",
    "\n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1705236693838,
     "user": {
      "displayName": "guang han",
      "userId": "09096391548724575519"
     },
     "user_tz": -480
    },
    "id": "awB5Gk9-BC67"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader = prepare_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ai_input_ids': tensor([[    1, 10147, 11311,  ...,     0,     0,     0],\n",
       "         [    1, 10147, 11311,  ...,     0,     0,     0],\n",
       "         [    1,  5388,   343,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    1,   279,  1806,  ...,     0,     0,     0],\n",
       "         [    1,  5388,   343,  ...,     0,     0,     0],\n",
       "         [    1,   273,   428,  ...,     0,     0,     0]]),\n",
       " 'ai_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'human_input_ids': tensor([[    1,  2489,   584,  ...,     0,     0,     0],\n",
       "         [    1, 10147,   264,  ...,     0,     0,     0],\n",
       "         [    1,   951,   837,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    1, 35706, 14962,  ...,     0,     0,     0],\n",
       "         [    1,   443,   281,  ...,   272,   301,     2],\n",
       "         [    1,  9232,  2691,  ...,     0,     0,     0]]),\n",
       " 'huamn_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'target': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = CONFIG['device']\n",
    "ai_input_ids = data['ai_input_ids'].to(device, dtype = torch.long)\n",
    "ai_attention_mask = data['ai_attention_mask'].to(device, dtype = torch.long)\n",
    "human_input_ids = data['human_input_ids'].to(device, dtype = torch.long)\n",
    "huamn_attention_mask = data['huamn_attention_mask'].to(device, dtype = torch.long)\n",
    "targets = data['target'].to(device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 10147, 11311,  ...,     0,     0,     0],\n",
       "        [    1, 10147, 11311,  ...,     0,     0,     0],\n",
       "        [    1,  5388,   343,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    1,   279,  1806,  ...,     0,     0,     0],\n",
       "        [    1,  5388,   343,  ...,     0,     0,     0],\n",
       "        [    1,   273,   428,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AiDectModel(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(CONFIG['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_outputs = model(ai_input_ids, ai_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
