{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db58bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ec8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n",
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import lightgbm\n",
    "\n",
    "print(sklearn.__version__)\n",
    "print(lightgbm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8746d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/test_essays.csv')\n",
    "sub = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/sample_submission.csv')\n",
    "org_train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/train_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774cc0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/daigt/train_v2_drcat_02.csv', sep=',')\n",
    "display(train.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b3f5c",
   "metadata": {},
   "source": [
    "#### Read and append the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950181df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18894, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_gen_data = pd.read_parquet('/home/peng_sun2/s3shared/kaggle/llm-2023/external_data/gen_data_21122023.parquet')\n",
    "display(train_gen_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8ff17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates(subset = ['text'])\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "\n",
    "### append the generated data\n",
    "# train = pd.concat([train, train_gen_data], axis = 0).reset_index(drop = True)\n",
    "# display(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f647664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWERCASE = False\n",
    "VOCAB_SIZE = 30522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b4831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create byte-pair encoding tokenizer\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token='[UNK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb8ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding normalization and pre_tokenizer\n",
    "raw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()]+ [normalizers.Lowercase()] if LOWERCASE else [])\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f33614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding special tokens and creating trainer instance\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size = VOCAB_SIZE, special_tokens = special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08980728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/pyarrow/pandas_compat.py:358: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018885374069213867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181a5628c000444d945daba138f730a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017849445343017578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 44868,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57071a95638420c90663aaa4d7de8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating huggingface dataset object\n",
    "dataset = Dataset.from_pandas(test[['text']])\n",
    "def train_corp_iter():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i:i+1000]['text']\n",
    "raw_tokenizer.train_from_iterator(train_corp_iter(), trainer = trainer)\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "tokenized_texts_test = []\n",
    "for text in tqdm(test['text'].tolist()):\n",
    "    tokenized_texts_test.append(tokenizer.tokenize(text))\n",
    "\n",
    "tokenized_texts_train = []\n",
    "\n",
    "for text in tqdm(train['text'].tolist()):\n",
    "    tokenized_texts_train.append(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f7ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ĠBbb', 'Ġccc', 'Ġddd', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93001dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c63bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ĠAaa Ġbbb Ġccc': 0, 'Ġbbb Ġccc .': 6, 'ĠAaa Ġbbb Ġccc .': 1, 'ĠBbb Ġccc Ġddd': 2, 'Ġccc Ġddd .': 7, 'ĠBbb Ġccc Ġddd .': 3, 'ĠCCC Ġddd Ġeee': 4, 'Ġddd Ġeee .': 8, 'ĠCCC Ġddd Ġeee .': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (3, 5), lowercase=False, sublinear_tf = True, analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None,\n",
    "                            strip_accents = 'unicode')\n",
    "vectorizer.fit(tokenized_texts_test)\n",
    "\n",
    "# Getting vocab\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, \n",
    "                             #vocabulary=vocab,\n",
    "                            analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None, strip_accents='unicode'\n",
    "                            )\n",
    "\n",
    "tf_train = vectorizer.fit_transform(tokenized_texts_train)\n",
    "tf_test = vectorizer.transform(tokenized_texts_test)\n",
    "## get the vocabulary of the training dataset\n",
    "train_vocab = vectorizer.vocabulary_\n",
    "\n",
    "del vectorizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff0482d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c0db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/peng_sun2/s3shared/kaggle/llm-2023/baseline1/vocab_train.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### save train_vocab\n",
    "import joblib\n",
    "model_path = '/home/peng_sun2/s3shared/kaggle/llm-2023/baseline1/'\n",
    "joblib.dump(train_vocab, f'{model_path}vocab_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "024a6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3c74dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Check if it's in scoring stage\n",
    "# if len(test.text.values) <= 5:\n",
    "#     # if not, just sample submission\n",
    "#     sub.to_csv('submission.csv', index=False)\n",
    "# else:\n",
    "# otherwise, run fitting process\n",
    "clf = MultinomialNB(alpha=0.02)\n",
    "clf2 = MultinomialNB(alpha=0.01)\n",
    "sgd_model = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\") \n",
    "p6={\n",
    "    'n_iter': 1500,\n",
    "    'verbose': -1,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05073909898961407, \n",
    "    'colsample_bytree': 0.726023996436955, \n",
    "    'colsample_bynode': 0.5803681307354022, \n",
    "    'lambda_l1': 8.562963348932286, \n",
    "    'lambda_l2': 4.893256185259296, \n",
    "    'min_data_in_leaf': 115, \n",
    "    'max_depth': 123, \n",
    "    'max_bin': 900,\n",
    "    #'device': 'gpu'\n",
    "}\n",
    "lgb=LGBMClassifier(**p6)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat=CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    verbose=0,\n",
    "    l2_leaf_reg=6.6591278779517808,\n",
    "    learning_rate=0.005689066836106983,\n",
    "    allow_const_label=True\n",
    ")\n",
    "#weights = [0.1, 0.45, 0.45, 0.45]\n",
    "weights = [0.1]\n",
    "weights = [w/sum(weights) for w in weights]\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "#       ('mnb',clf),\n",
    "        ('sgd', sgd_model),\n",
    "#          ('lgb',lgb), \n",
    "#         ('cat', cat)\n",
    "    ],\n",
    "    weights=weights, \n",
    "    voting='soft', n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1841a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peng_sun2/.local/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/sklearn/ensemble/_base.py\", line 46, in _fit_single_estimator\n    estimator.fit(X, y)\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n    self._Booster = train(\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n    _safe_call(_LIB.LGBM_BoosterCreate(\n  File \"/home/peng_sun2/.local/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\nlightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m \u001b[43mensemble\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## output the models\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/peng_sun2/s3shared/kaggle/llm-2023/baseline1/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:346\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    344\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "ensemble.fit(tf_train, y_train )\n",
    "## output the models\n",
    "model_path = '/home/peng_sun2/s3shared/kaggle/llm-2023/baseline1/'\n",
    "# joblib.dump(clf, f'{model_path}clf.pkl');\n",
    "# joblib.dump(sgd_model, f'{model_path}sgd_model.pkl')\n",
    "# joblib.dump(lgb, f'{model_path}lgb.pkl')\n",
    "# joblib.dump(cat, f'{model_path}cat.pkl')\n",
    "joblib.dump(ensemble, f'{model_path}ensemble.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e31cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bf101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble.predict(tf_train[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e82ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35894, 20784)\n",
      "eval preds:\n",
      "[0.         0.         0.06913218 ... 1.         1.         1.        ]\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 1.82648402e-04\n",
      " 1.82648402e-04 3.65296804e-04 3.65296804e-04 5.47945205e-04\n",
      " 5.47945205e-04 7.30593607e-04 7.30593607e-04 9.13242009e-04\n",
      " 9.13242009e-04 1.09589041e-03 1.09589041e-03 1.27853881e-03\n",
      " 1.27853881e-03 1.46118721e-03 1.46118721e-03 1.64383562e-03\n",
      " 1.64383562e-03 1.82648402e-03 1.82648402e-03 2.00913242e-03\n",
      " 2.00913242e-03 2.19178082e-03 2.19178082e-03 2.37442922e-03\n",
      " 2.37442922e-03 2.55707763e-03 2.55707763e-03 2.73972603e-03\n",
      " 2.73972603e-03 2.92237443e-03 2.92237443e-03 3.10502283e-03\n",
      " 3.10502283e-03 3.28767123e-03 3.28767123e-03 3.47031963e-03\n",
      " 3.47031963e-03 3.65296804e-03 3.65296804e-03 3.83561644e-03\n",
      " 3.83561644e-03 4.20091324e-03 4.20091324e-03 4.38356164e-03\n",
      " 4.38356164e-03 4.56621005e-03 4.56621005e-03 4.74885845e-03\n",
      " 4.74885845e-03 4.93150685e-03 4.93150685e-03 5.11415525e-03\n",
      " 5.11415525e-03 5.47945205e-03 5.47945205e-03 5.66210046e-03\n",
      " 5.66210046e-03 5.84474886e-03 5.84474886e-03 6.02739726e-03\n",
      " 6.02739726e-03 6.21004566e-03 6.21004566e-03 6.39269406e-03\n",
      " 6.39269406e-03 6.57534247e-03 6.57534247e-03 6.75799087e-03\n",
      " 6.75799087e-03 6.94063927e-03 6.94063927e-03 7.30593607e-03\n",
      " 7.30593607e-03 7.48858447e-03 7.48858447e-03 7.67123288e-03\n",
      " 7.67123288e-03 7.85388128e-03 7.85388128e-03 8.21917808e-03\n",
      " 8.21917808e-03 8.40182648e-03 8.40182648e-03 8.58447489e-03\n",
      " 8.58447489e-03 8.94977169e-03 8.94977169e-03 9.31506849e-03\n",
      " 9.31506849e-03 9.68036530e-03 9.68036530e-03 9.86301370e-03\n",
      " 9.86301370e-03 1.00456621e-02 1.00456621e-02 1.02283105e-02\n",
      " 1.02283105e-02 1.04109589e-02 1.04109589e-02 1.05936073e-02\n",
      " 1.05936073e-02 1.09589041e-02 1.09589041e-02 1.11415525e-02\n",
      " 1.11415525e-02 1.16894977e-02 1.16894977e-02 1.18721461e-02\n",
      " 1.18721461e-02 1.20547945e-02 1.20547945e-02 1.22374429e-02\n",
      " 1.22374429e-02 1.38812785e-02 1.38812785e-02 1.40639269e-02\n",
      " 1.40639269e-02 1.42465753e-02 1.42465753e-02 1.46118721e-02\n",
      " 1.46118721e-02 1.47945205e-02 1.47945205e-02 1.53424658e-02\n",
      " 1.53424658e-02 1.55251142e-02 1.55251142e-02 1.58904110e-02\n",
      " 1.58904110e-02 1.66210046e-02 1.66210046e-02 1.71689498e-02\n",
      " 1.71689498e-02 1.82648402e-02 1.82648402e-02 1.91780822e-02\n",
      " 1.91780822e-02 1.93607306e-02 1.93607306e-02 1.95433790e-02\n",
      " 1.95433790e-02 1.99086758e-02 1.99086758e-02 2.08219178e-02\n",
      " 2.08219178e-02 2.10045662e-02 2.10045662e-02 2.11872146e-02\n",
      " 2.11872146e-02 2.19178082e-02 2.19178082e-02 2.28310502e-02\n",
      " 2.28310502e-02 2.37442922e-02 2.37442922e-02 2.46575342e-02\n",
      " 2.46575342e-02 2.57534247e-02 2.57534247e-02 2.64840183e-02\n",
      " 2.64840183e-02 2.68493151e-02 2.68493151e-02 2.70319635e-02\n",
      " 2.70319635e-02 2.77625571e-02 2.77625571e-02 2.79452055e-02\n",
      " 2.79452055e-02 2.81278539e-02 2.81278539e-02 3.06849315e-02\n",
      " 3.06849315e-02 3.30593607e-02 3.30593607e-02 3.50684932e-02\n",
      " 3.50684932e-02 3.57990868e-02 3.57990868e-02 3.63470320e-02\n",
      " 3.63470320e-02 3.74429224e-02 3.74429224e-02 4.01826484e-02\n",
      " 4.01826484e-02 4.09132420e-02 4.09132420e-02 4.10958904e-02\n",
      " 4.10958904e-02 4.29223744e-02 4.29223744e-02 4.43835616e-02\n",
      " 4.43835616e-02 4.47488584e-02 4.47488584e-02 4.60273973e-02\n",
      " 4.60273973e-02 4.67579909e-02 4.67579909e-02 4.80365297e-02\n",
      " 4.80365297e-02 4.82191781e-02 4.82191781e-02 4.85844749e-02\n",
      " 4.85844749e-02 4.93150685e-02 4.93150685e-02 5.04109589e-02\n",
      " 5.04109589e-02 5.22374429e-02 5.22374429e-02 5.24200913e-02\n",
      " 5.24200913e-02 5.42465753e-02 5.42465753e-02 5.93607306e-02\n",
      " 5.93607306e-02 6.10045662e-02 6.10045662e-02 6.24657534e-02\n",
      " 6.24657534e-02 6.28310502e-02 6.28310502e-02 6.61187215e-02\n",
      " 6.61187215e-02 6.64840183e-02 6.64840183e-02 6.88584475e-02\n",
      " 6.88584475e-02 6.97716895e-02 6.97716895e-02 7.05022831e-02\n",
      " 7.05022831e-02 7.34246575e-02 7.34246575e-02 7.43378995e-02\n",
      " 7.43378995e-02 7.54337900e-02 7.54337900e-02 7.74429224e-02\n",
      " 7.74429224e-02 8.09132420e-02 8.09132420e-02 8.16438356e-02\n",
      " 8.16438356e-02 8.31050228e-02 8.31050228e-02 8.74885845e-02\n",
      " 8.74885845e-02 9.89954338e-02 9.89954338e-02 1.00091324e-01\n",
      " 1.00091324e-01 1.08127854e-01 1.08127854e-01 1.27305936e-01\n",
      " 1.27305936e-01 1.28401826e-01 1.28401826e-01 1.51780822e-01\n",
      " 1.51780822e-01 1.54520548e-01 1.54520548e-01 1.70593607e-01\n",
      " 1.70593607e-01 2.05296804e-01 2.05296804e-01 2.09132420e-01\n",
      " 2.09132420e-01 2.12602740e-01 2.12602740e-01 2.81278539e-01\n",
      " 2.81278539e-01 2.92602740e-01 2.92602740e-01 3.24931507e-01\n",
      " 3.24931507e-01 3.32420091e-01 1.00000000e+00] [0.         0.70848814 0.78079451 0.78079451 0.79022578 0.79022578\n",
      " 0.82880823 0.82880823 0.83966848 0.83966848 0.85252929 0.85252929\n",
      " 0.85338668 0.85338668 0.85624464 0.85624464 0.86967705 0.86967705\n",
      " 0.87739354 0.87739354 0.88796799 0.88796799 0.89054015 0.89054015\n",
      " 0.89196913 0.89196913 0.90282938 0.90282938 0.90340097 0.90340097\n",
      " 0.90540154 0.90540154 0.91026007 0.91026007 0.91969134 0.91969134\n",
      " 0.9225493  0.9225493  0.92454987 0.92454987 0.92569306 0.92569306\n",
      " 0.93026579 0.93026579 0.93055159 0.93055159 0.93198057 0.93198057\n",
      " 0.93283795 0.93283795 0.93312375 0.93312375 0.93569591 0.93569591\n",
      " 0.93712489 0.93712489 0.93941126 0.93941126 0.94112604 0.94112604\n",
      " 0.94226922 0.94226922 0.9436982  0.9436982  0.94941412 0.94941412\n",
      " 0.9505573  0.9505573  0.95141469 0.95141469 0.95227208 0.95227208\n",
      " 0.95284367 0.95284367 0.95341526 0.95341526 0.95455845 0.95455845\n",
      " 0.95541583 0.95541583 0.95598742 0.95598742 0.9577022  0.9577022\n",
      " 0.957988   0.957988   0.95827379 0.95827379 0.95970277 0.95970277\n",
      " 0.96027436 0.96027436 0.96084596 0.96084596 0.96198914 0.96198914\n",
      " 0.96256073 0.96256073 0.96284653 0.96284653 0.96313232 0.96313232\n",
      " 0.96398971 0.96398971 0.9651329  0.9651329  0.96599028 0.96599028\n",
      " 0.96656187 0.96656187 0.96684767 0.96684767 0.96713347 0.96713347\n",
      " 0.96741926 0.96741926 0.96770506 0.96770506 0.96856245 0.96856245\n",
      " 0.96884824 0.96884824 0.96913404 0.96913404 0.96970563 0.96970563\n",
      " 0.96999143 0.96999143 0.97027722 0.97027722 0.97084881 0.97084881\n",
      " 0.97113461 0.97113461 0.97227779 0.97227779 0.97284939 0.97284939\n",
      " 0.97342098 0.97342098 0.97370677 0.97370677 0.97427837 0.97427837\n",
      " 0.97456416 0.97456416 0.97513575 0.97513575 0.97599314 0.97599314\n",
      " 0.97627894 0.97627894 0.97742212 0.97742212 0.97799371 0.97799371\n",
      " 0.9788511  0.9788511  0.9791369  0.9791369  0.97970849 0.97970849\n",
      " 0.97999428 0.97999428 0.98028008 0.98028008 0.98056588 0.98056588\n",
      " 0.98085167 0.98085167 0.98113747 0.98113747 0.98142326 0.98142326\n",
      " 0.98170906 0.98170906 0.98199486 0.98199486 0.98228065 0.98228065\n",
      " 0.98256645 0.98256645 0.98285224 0.98285224 0.98313804 0.98313804\n",
      " 0.98342384 0.98342384 0.98370963 0.98370963 0.98399543 0.98399543\n",
      " 0.98428122 0.98428122 0.98485282 0.98485282 0.98542441 0.98542441\n",
      " 0.9857102  0.9857102  0.985996   0.985996   0.98628179 0.98628179\n",
      " 0.98656759 0.98656759 0.98713918 0.98713918 0.98742498 0.98742498\n",
      " 0.98771077 0.98771077 0.98799657 0.98799657 0.98828237 0.98828237\n",
      " 0.98856816 0.98856816 0.98885396 0.98885396 0.98913975 0.98913975\n",
      " 0.98942555 0.98942555 0.98971135 0.98971135 0.98999714 0.98999714\n",
      " 0.99056873 0.99056873 0.99085453 0.99085453 0.99114033 0.99114033\n",
      " 0.99142612 0.99142612 0.99171192 0.99171192 0.99228351 0.99228351\n",
      " 0.99256931 0.99256931 0.9928551  0.9928551  0.9931409  0.9931409\n",
      " 0.99342669 0.99342669 0.99371249 0.99371249 0.99399829 0.99399829\n",
      " 0.99428408 0.99428408 0.99456988 0.99456988 0.99485567 0.99485567\n",
      " 0.99514147 0.99514147 0.99542726 0.99542726 0.99571306 0.99571306\n",
      " 0.99599886 0.99599886 0.99628465 0.99628465 0.99657045 0.99657045\n",
      " 0.99685624 0.99685624 0.99714204 0.99714204 0.99742784 0.99742784\n",
      " 0.99771363 0.99771363 0.99799943 0.99799943 0.99828522 0.99828522\n",
      " 1.        ]\n",
      "0.9966875336854236\n",
      "(35894, 20784)\n",
      "eval preds:\n",
      "[0.         0.         0.         ... 0.74546891 1.         1.        ]\n",
      "[0.         0.00182682 0.00182682 0.0020095  0.0020095  0.00219218\n",
      " 0.00219218 0.00255754 0.00255754 0.00274023 0.00274023 0.00292291\n",
      " 0.00292291 0.00310559 0.00310559 0.00328827 0.00328827 0.00347095\n",
      " 0.00347095 0.00365364 0.00365364 0.00383632 0.00383632 0.004019\n",
      " 0.004019   0.00420168 0.00420168 0.00438436 0.00438436 0.00456704\n",
      " 0.00456704 0.00474973 0.00474973 0.00493241 0.00493241 0.00511509\n",
      " 0.00511509 0.00529777 0.00529777 0.00548045 0.00548045 0.00584582\n",
      " 0.00584582 0.0060285  0.0060285  0.00639386 0.00639386 0.00657654\n",
      " 0.00657654 0.00675923 0.00675923 0.00694191 0.00694191 0.00712459\n",
      " 0.00712459 0.00730727 0.00730727 0.00748995 0.00748995 0.00767263\n",
      " 0.00767263 0.00785532 0.00785532 0.008038   0.008038   0.00822068\n",
      " 0.00822068 0.00840336 0.00840336 0.00858604 0.00858604 0.00876872\n",
      " 0.00876872 0.00895141 0.00895141 0.00931677 0.00931677 0.00949945\n",
      " 0.00949945 0.00968213 0.00968213 0.00986482 0.00986482 0.0100475\n",
      " 0.0100475  0.01023018 0.01023018 0.01041286 0.01041286 0.01059554\n",
      " 0.01059554 0.01077822 0.01077822 0.01150895 0.01150895 0.01169163\n",
      " 0.01169163 0.01187431 0.01187431 0.01242236 0.01242236 0.01297041\n",
      " 0.01297041 0.01443186 0.01443186 0.01461454 0.01461454 0.01516259\n",
      " 0.01516259 0.01534527 0.01534527 0.01589331 0.01589331 0.01644136\n",
      " 0.01644136 0.01680672 0.01680672 0.0169894  0.0169894  0.01735477\n",
      " 0.01735477 0.01790281 0.01790281 0.0180855  0.0180855  0.01845086\n",
      " 0.01845086 0.01881622 0.01881622 0.01936427 0.01936427 0.01972963\n",
      " 0.01972963 0.02009499 0.02009499 0.02027768 0.02027768 0.02064304\n",
      " 0.02064304 0.0210084  0.0210084  0.02119109 0.02119109 0.02137377\n",
      " 0.02137377 0.02173913 0.02173913 0.02192181 0.02192181 0.02210449\n",
      " 0.02210449 0.02265254 0.02265254 0.0230179  0.0230179  0.02320058\n",
      " 0.02320058 0.02374863 0.02374863 0.02393131 0.02393131 0.02484472\n",
      " 0.02484472 0.02557545 0.02557545 0.02612349 0.02612349 0.02630617\n",
      " 0.02630617 0.02685422 0.02685422 0.02758495 0.02758495 0.02795031\n",
      " 0.02795031 0.02813299 0.02813299 0.02831567 0.02831567 0.0290464\n",
      " 0.0290464  0.02995981 0.02995981 0.03087322 0.03087322 0.03123858\n",
      " 0.03123858 0.03251735 0.03251735 0.03288272 0.03288272 0.03324808\n",
      " 0.03324808 0.03452685 0.03452685 0.0350749  0.0350749  0.03544026\n",
      " 0.03544026 0.03562294 0.03562294 0.03653635 0.03653635 0.03671904\n",
      " 0.03671904 0.0370844  0.0370844  0.03763244 0.03763244 0.03781513\n",
      " 0.03781513 0.03872853 0.03872853 0.03927658 0.03927658 0.03945926\n",
      " 0.03945926 0.04493972 0.04493972 0.04548776 0.04548776 0.04640117\n",
      " 0.04640117 0.04731458 0.04731458 0.04767994 0.04767994 0.04786262\n",
      " 0.04786262 0.04804531 0.04804531 0.04822799 0.04822799 0.04841067\n",
      " 0.04841067 0.04987212 0.04987212 0.05023749 0.05023749 0.05060285\n",
      " 0.05060285 0.0511509  0.0511509  0.05151626 0.05151626 0.05188162\n",
      " 0.05188162 0.0520643  0.0520643  0.05224699 0.05224699 0.05242967\n",
      " 0.05242967 0.05297771 0.05297771 0.0540738  0.0540738  0.05644867\n",
      " 0.05644867 0.05717939 0.05717939 0.05991962 0.05991962 0.06320789\n",
      " 0.06320789 0.06375594 0.06375594 0.0661308  0.0661308  0.06759225\n",
      " 0.06759225 0.06795762 0.06795762 0.06887103 0.06887103 0.06941907\n",
      " 0.06941907 0.06996712 0.06996712 0.07325539 0.07325539 0.0741688\n",
      " 0.0741688  0.07508221 0.07508221 0.07636098 0.07636098 0.07782243\n",
      " 0.07782243 0.07891852 0.07891852 0.08257216 0.08257216 0.08385093\n",
      " 0.08385093 0.0842163  0.0842163  0.08659116 0.08659116 0.08805261\n",
      " 0.08805261 0.08841798 0.08841798 0.09024479 0.09024479 0.09535988\n",
      " 0.09535988 0.09736938 0.09736938 0.09773475 0.09773475 0.10102302\n",
      " 0.10102302 0.10449397 0.10449397 0.10705152 0.10705152 0.10997442\n",
      " 0.10997442 0.12056997 0.12056997 0.12075265 0.12075265 0.12166606\n",
      " 0.12166606 0.12349288 0.12349288 0.12641578 0.12641578 0.12732919\n",
      " 0.12732919 0.12751187 0.12751187 0.12915601 0.12915601 0.13682864\n",
      " 0.13682864 0.13810742 0.13810742 0.1402996  0.1402996  0.14267446\n",
      " 0.14267446 0.14669346 0.14669346 0.15308732 0.15308732 0.15582755\n",
      " 0.15582755 0.16149068 0.16149068 0.17592254 0.17592254 0.1793935\n",
      " 0.1793935  0.18268177 0.18268177 0.18414322 0.18414322 0.20533431\n",
      " 0.20533431 0.24132262 0.24132262 0.26470588 0.26470588 0.31951041\n",
      " 0.31951041 0.33832664 0.33832664 0.38856412 0.38856412 0.39093898\n",
      " 0.39093898 0.44501279 0.44501279 0.44775301 0.44775301 0.50767263\n",
      " 0.50767263 0.51772013 1.        ] [0.         0.74371429 0.74685714 0.74685714 0.786      0.786\n",
      " 0.81142857 0.81142857 0.83571429 0.83571429 0.836      0.836\n",
      " 0.85       0.85       0.85457143 0.85457143 0.85685714 0.85685714\n",
      " 0.86657143 0.86657143 0.86828571 0.86828571 0.86914286 0.86914286\n",
      " 0.874      0.874      0.87628571 0.87628571 0.87685714 0.87685714\n",
      " 0.87742857 0.87742857 0.87828571 0.87828571 0.88       0.88\n",
      " 0.88685714 0.88685714 0.88971429 0.88971429 0.89971429 0.89971429\n",
      " 0.90228571 0.90228571 0.90428571 0.90428571 0.90542857 0.90542857\n",
      " 0.906      0.906      0.90828571 0.90828571 0.90857143 0.90857143\n",
      " 0.91771429 0.91771429 0.91914286 0.91914286 0.92       0.92\n",
      " 0.92142857 0.92142857 0.92171429 0.92171429 0.92314286 0.92314286\n",
      " 0.92342857 0.92342857 0.92742857 0.92742857 0.92971429 0.92971429\n",
      " 0.93       0.93       0.93085714 0.93085714 0.932      0.932\n",
      " 0.93371429 0.93371429 0.934      0.934      0.93657143 0.93657143\n",
      " 0.938      0.938      0.93885714 0.93885714 0.94085714 0.94085714\n",
      " 0.94142857 0.94142857 0.94171429 0.94171429 0.94228571 0.94228571\n",
      " 0.94285714 0.94285714 0.94314286 0.94314286 0.94342857 0.94342857\n",
      " 0.944      0.944      0.94514286 0.94514286 0.94542857 0.94542857\n",
      " 0.94628571 0.94628571 0.94657143 0.94657143 0.948      0.948\n",
      " 0.94885714 0.94885714 0.95257143 0.95257143 0.95285714 0.95285714\n",
      " 0.95314286 0.95314286 0.95342857 0.95342857 0.95371429 0.95371429\n",
      " 0.954      0.954      0.95457143 0.95457143 0.95485714 0.95485714\n",
      " 0.95571429 0.95571429 0.95657143 0.95657143 0.95714286 0.95714286\n",
      " 0.95771429 0.95771429 0.95828571 0.95828571 0.95885714 0.95885714\n",
      " 0.95914286 0.95914286 0.95942857 0.95942857 0.96028571 0.96028571\n",
      " 0.96057143 0.96057143 0.96085714 0.96085714 0.96114286 0.96114286\n",
      " 0.962      0.962      0.96285714 0.96285714 0.96371429 0.96371429\n",
      " 0.964      0.964      0.96485714 0.96485714 0.96514286 0.96514286\n",
      " 0.96542857 0.96542857 0.96571429 0.96571429 0.966      0.966\n",
      " 0.96657143 0.96657143 0.96685714 0.96685714 0.96714286 0.96714286\n",
      " 0.96742857 0.96742857 0.968      0.968      0.96828571 0.96828571\n",
      " 0.96914286 0.96914286 0.96942857 0.96942857 0.96971429 0.96971429\n",
      " 0.97       0.97       0.97028571 0.97028571 0.97057143 0.97057143\n",
      " 0.97085714 0.97085714 0.97142857 0.97142857 0.97171429 0.97171429\n",
      " 0.972      0.972      0.97228571 0.97228571 0.97285714 0.97285714\n",
      " 0.97314286 0.97314286 0.97342857 0.97342857 0.974      0.974\n",
      " 0.97428571 0.97428571 0.97457143 0.97457143 0.97485714 0.97485714\n",
      " 0.97514286 0.97514286 0.97542857 0.97542857 0.97571429 0.97571429\n",
      " 0.976      0.976      0.97628571 0.97628571 0.97685714 0.97685714\n",
      " 0.97742857 0.97742857 0.97771429 0.97771429 0.978      0.978\n",
      " 0.97828571 0.97828571 0.97857143 0.97857143 0.97885714 0.97885714\n",
      " 0.97914286 0.97914286 0.97942857 0.97942857 0.97971429 0.97971429\n",
      " 0.98       0.98       0.98057143 0.98057143 0.98085714 0.98085714\n",
      " 0.98114286 0.98114286 0.98142857 0.98142857 0.98171429 0.98171429\n",
      " 0.982      0.982      0.98228571 0.98228571 0.98257143 0.98257143\n",
      " 0.98285714 0.98285714 0.98314286 0.98314286 0.98342857 0.98342857\n",
      " 0.98371429 0.98371429 0.984      0.984      0.98428571 0.98428571\n",
      " 0.98457143 0.98457143 0.98485714 0.98485714 0.98542857 0.98542857\n",
      " 0.98571429 0.98571429 0.986      0.986      0.98628571 0.98628571\n",
      " 0.98685714 0.98685714 0.98714286 0.98714286 0.98771429 0.98771429\n",
      " 0.988      0.988      0.98828571 0.98828571 0.98857143 0.98857143\n",
      " 0.98885714 0.98885714 0.98914286 0.98914286 0.98942857 0.98942857\n",
      " 0.98971429 0.98971429 0.99       0.99       0.99028571 0.99028571\n",
      " 0.99057143 0.99057143 0.99085714 0.99085714 0.99114286 0.99114286\n",
      " 0.99142857 0.99142857 0.99171429 0.99171429 0.992      0.992\n",
      " 0.99228571 0.99228571 0.99257143 0.99257143 0.99285714 0.99285714\n",
      " 0.99314286 0.99314286 0.99342857 0.99342857 0.99371429 0.99371429\n",
      " 0.994      0.994      0.99428571 0.99428571 0.99457143 0.99457143\n",
      " 0.99485714 0.99485714 0.99514286 0.99514286 0.99542857 0.99542857\n",
      " 0.99571429 0.99571429 0.996      0.996      0.99628571 0.99628571\n",
      " 0.99657143 0.99657143 0.99685714 0.99685714 0.99714286 0.99714286\n",
      " 0.99742857 0.99742857 0.99771429 0.99771429 0.998      0.998\n",
      " 0.99828571 0.99828571 0.99857143 0.99857143 0.99885714 0.99885714\n",
      " 0.99914286 0.99914286 1.        ]\n",
      "0.9941866485724724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35894, 20784)\n",
      "eval preds:\n",
      "[0.20180468 0.         0.22394656 ... 1.         1.         1.        ]\n",
      "[0.00000000e+00 1.82681768e-04 1.82681768e-04 3.65363537e-04\n",
      " 3.65363537e-04 5.48045305e-04 5.48045305e-04 7.30727073e-04\n",
      " 7.30727073e-04 9.13408842e-04 9.13408842e-04 1.09609061e-03\n",
      " 1.09609061e-03 1.27877238e-03 1.27877238e-03 1.46145415e-03\n",
      " 1.46145415e-03 1.82681768e-03 1.82681768e-03 2.00949945e-03\n",
      " 2.00949945e-03 2.19218122e-03 2.19218122e-03 2.37486299e-03\n",
      " 2.37486299e-03 2.55754476e-03 2.55754476e-03 2.74022653e-03\n",
      " 2.74022653e-03 3.10559006e-03 3.10559006e-03 3.28827183e-03\n",
      " 3.28827183e-03 3.47095360e-03 3.47095360e-03 3.65363537e-03\n",
      " 3.65363537e-03 4.01899890e-03 4.01899890e-03 4.20168067e-03\n",
      " 4.20168067e-03 4.56704421e-03 4.56704421e-03 4.74972598e-03\n",
      " 4.74972598e-03 4.93240775e-03 4.93240775e-03 5.11508951e-03\n",
      " 5.11508951e-03 5.29777128e-03 5.29777128e-03 5.48045305e-03\n",
      " 5.48045305e-03 5.66313482e-03 5.66313482e-03 5.84581659e-03\n",
      " 5.84581659e-03 6.02849836e-03 6.02849836e-03 6.21118012e-03\n",
      " 6.21118012e-03 6.57654366e-03 6.57654366e-03 6.75922543e-03\n",
      " 6.75922543e-03 6.94190720e-03 6.94190720e-03 7.12458897e-03\n",
      " 7.12458897e-03 7.30727073e-03 7.30727073e-03 7.48995250e-03\n",
      " 7.48995250e-03 7.67263427e-03 7.67263427e-03 8.40336134e-03\n",
      " 8.40336134e-03 8.58604311e-03 8.58604311e-03 8.95140665e-03\n",
      " 8.95140665e-03 9.13408842e-03 9.13408842e-03 9.31677019e-03\n",
      " 9.31677019e-03 9.68213372e-03 9.68213372e-03 1.00474973e-02\n",
      " 1.00474973e-02 1.04128608e-02 1.04128608e-02 1.05955426e-02\n",
      " 1.05955426e-02 1.09609061e-02 1.09609061e-02 1.13262696e-02\n",
      " 1.13262696e-02 1.15089514e-02 1.15089514e-02 1.20569967e-02\n",
      " 1.20569967e-02 1.24223602e-02 1.24223602e-02 1.26050420e-02\n",
      " 1.26050420e-02 1.29704056e-02 1.29704056e-02 1.31530873e-02\n",
      " 1.31530873e-02 1.33357691e-02 1.33357691e-02 1.35184509e-02\n",
      " 1.35184509e-02 1.38838144e-02 1.38838144e-02 1.42491779e-02\n",
      " 1.42491779e-02 1.46145415e-02 1.46145415e-02 1.49799050e-02\n",
      " 1.49799050e-02 1.51625868e-02 1.51625868e-02 1.55279503e-02\n",
      " 1.55279503e-02 1.57106321e-02 1.57106321e-02 1.58933138e-02\n",
      " 1.58933138e-02 1.60759956e-02 1.60759956e-02 1.62586774e-02\n",
      " 1.62586774e-02 1.66240409e-02 1.66240409e-02 1.68067227e-02\n",
      " 1.68067227e-02 1.73547680e-02 1.73547680e-02 1.77201315e-02\n",
      " 1.77201315e-02 1.79028133e-02 1.79028133e-02 1.84508586e-02\n",
      " 1.84508586e-02 1.95469492e-02 1.95469492e-02 1.97296310e-02\n",
      " 1.97296310e-02 2.00949945e-02 2.00949945e-02 2.02776763e-02\n",
      " 2.02776763e-02 2.10084034e-02 2.10084034e-02 2.11910851e-02\n",
      " 2.11910851e-02 2.26525393e-02 2.26525393e-02 2.35659481e-02\n",
      " 2.35659481e-02 2.37486299e-02 2.37486299e-02 2.42966752e-02\n",
      " 2.42966752e-02 2.46620387e-02 2.46620387e-02 2.52100840e-02\n",
      " 2.52100840e-02 2.68542199e-02 2.68542199e-02 2.72195835e-02\n",
      " 2.72195835e-02 2.79503106e-02 2.79503106e-02 2.90464012e-02\n",
      " 2.90464012e-02 2.94117647e-02 2.94117647e-02 3.10559006e-02\n",
      " 3.10559006e-02 3.12385824e-02 3.12385824e-02 3.19693095e-02\n",
      " 3.19693095e-02 3.21519912e-02 3.21519912e-02 3.25173548e-02\n",
      " 3.25173548e-02 3.39788089e-02 3.39788089e-02 3.41614907e-02\n",
      " 3.41614907e-02 3.43441725e-02 3.43441725e-02 3.47095360e-02\n",
      " 3.47095360e-02 3.54402631e-02 3.54402631e-02 3.63536719e-02\n",
      " 3.63536719e-02 3.67190354e-02 3.67190354e-02 3.78151261e-02\n",
      " 3.78151261e-02 3.79978078e-02 3.79978078e-02 3.85458531e-02\n",
      " 3.85458531e-02 3.89112167e-02 3.89112167e-02 4.09207161e-02\n",
      " 4.09207161e-02 4.11033979e-02 4.11033979e-02 4.21994885e-02\n",
      " 4.21994885e-02 4.34782609e-02 4.34782609e-02 4.47570332e-02\n",
      " 4.47570332e-02 4.51223968e-02 4.51223968e-02 4.58531239e-02\n",
      " 4.58531239e-02 4.60358056e-02 4.60358056e-02 5.02374863e-02\n",
      " 5.02374863e-02 5.22469858e-02 5.22469858e-02 5.31603946e-02\n",
      " 5.31603946e-02 5.35257581e-02 5.35257581e-02 5.37084399e-02\n",
      " 5.37084399e-02 5.46218487e-02 5.46218487e-02 5.73620753e-02\n",
      " 5.73620753e-02 5.77274388e-02 5.77274388e-02 5.90062112e-02\n",
      " 5.90062112e-02 6.15637559e-02 6.15637559e-02 6.39386189e-02\n",
      " 6.39386189e-02 6.66788455e-02 6.66788455e-02 6.94190720e-02\n",
      " 6.94190720e-02 7.41687980e-02 7.41687980e-02 7.59956156e-02\n",
      " 7.59956156e-02 8.03799781e-02 8.03799781e-02 8.09280234e-02\n",
      " 8.09280234e-02 8.18414322e-02 8.18414322e-02 8.23894775e-02\n",
      " 8.23894775e-02 8.65911582e-02 8.65911582e-02 8.86006577e-02\n",
      " 8.86006577e-02 8.87833394e-02 8.87833394e-02 8.98794300e-02\n",
      " 8.98794300e-02 9.24369748e-02 9.24369748e-02 9.29850201e-02\n",
      " 9.29850201e-02 9.38984289e-02 9.38984289e-02 1.00840336e-01\n",
      " 1.00840336e-01 1.01023018e-01 1.01023018e-01 1.04493972e-01\n",
      " 1.04493972e-01 1.05407380e-01 1.05407380e-01 1.06320789e-01\n",
      " 1.06320789e-01 1.07599562e-01 1.07599562e-01 1.19473877e-01\n",
      " 1.19473877e-01 1.25137011e-01 1.25137011e-01 1.25685057e-01\n",
      " 1.25685057e-01 1.33723054e-01 1.33723054e-01 1.33905736e-01\n",
      " 1.33905736e-01 1.34271100e-01 1.34271100e-01 1.45962733e-01\n",
      " 1.45962733e-01 1.50164414e-01 1.50164414e-01 1.55279503e-01\n",
      " 1.55279503e-01 1.64230910e-01 1.64230910e-01 1.66240409e-01\n",
      " 1.66240409e-01 1.72086226e-01 1.72086226e-01 1.83960541e-01\n",
      " 1.83960541e-01 1.93642674e-01 1.93642674e-01 1.99488491e-01\n",
      " 1.99488491e-01 2.03690172e-01 2.03690172e-01 2.30361710e-01\n",
      " 2.30361710e-01 2.43514797e-01 2.43514797e-01 3.07270734e-01\n",
      " 3.07270734e-01 3.32663500e-01 3.32663500e-01 3.83814395e-01\n",
      " 3.83814395e-01 4.24735111e-01 4.24735111e-01 4.47022287e-01\n",
      " 1.00000000e+00] [0.         0.706      0.764      0.764      0.778      0.778\n",
      " 0.79       0.79       0.79714286 0.79714286 0.81371429 0.81371429\n",
      " 0.81628571 0.81628571 0.81828571 0.81828571 0.85257143 0.85257143\n",
      " 0.85485714 0.85485714 0.85742857 0.85742857 0.85828571 0.85828571\n",
      " 0.85857143 0.85857143 0.85914286 0.85914286 0.86885714 0.86885714\n",
      " 0.87571429 0.87571429 0.88971429 0.88971429 0.89085714 0.89085714\n",
      " 0.892      0.892      0.89285714 0.89285714 0.89857143 0.89857143\n",
      " 0.90028571 0.90028571 0.90085714 0.90085714 0.90314286 0.90314286\n",
      " 0.90828571 0.90828571 0.90857143 0.90857143 0.90942857 0.90942857\n",
      " 0.91       0.91       0.91142857 0.91142857 0.912      0.912\n",
      " 0.91485714 0.91485714 0.91657143 0.91657143 0.91742857 0.91742857\n",
      " 0.918      0.918      0.91885714 0.91885714 0.92057143 0.92057143\n",
      " 0.92171429 0.92171429 0.92542857 0.92542857 0.92685714 0.92685714\n",
      " 0.92885714 0.92885714 0.93       0.93       0.93171429 0.93171429\n",
      " 0.932      0.932      0.93457143 0.93457143 0.93685714 0.93685714\n",
      " 0.94285714 0.94285714 0.94628571 0.94628571 0.948      0.948\n",
      " 0.95       0.95       0.95114286 0.95114286 0.95142857 0.95142857\n",
      " 0.95171429 0.95171429 0.952      0.952      0.95228571 0.95228571\n",
      " 0.95257143 0.95257143 0.95314286 0.95314286 0.95428571 0.95428571\n",
      " 0.95657143 0.95657143 0.95742857 0.95742857 0.95771429 0.95771429\n",
      " 0.95828571 0.95828571 0.95942857 0.95942857 0.96028571 0.96028571\n",
      " 0.96057143 0.96057143 0.96085714 0.96085714 0.96114286 0.96114286\n",
      " 0.962      0.962      0.96228571 0.96228571 0.96257143 0.96257143\n",
      " 0.96285714 0.96285714 0.96314286 0.96314286 0.96371429 0.96371429\n",
      " 0.96428571 0.96428571 0.96485714 0.96485714 0.966      0.966\n",
      " 0.96628571 0.96628571 0.96657143 0.96657143 0.96685714 0.96685714\n",
      " 0.96714286 0.96714286 0.96742857 0.96742857 0.968      0.968\n",
      " 0.96885714 0.96885714 0.97       0.97       0.97057143 0.97057143\n",
      " 0.97085714 0.97085714 0.97142857 0.97142857 0.97171429 0.97171429\n",
      " 0.972      0.972      0.97228571 0.97228571 0.97257143 0.97257143\n",
      " 0.97314286 0.97314286 0.974      0.974      0.97428571 0.97428571\n",
      " 0.97485714 0.97485714 0.97514286 0.97514286 0.97542857 0.97542857\n",
      " 0.97571429 0.97571429 0.976      0.976      0.97628571 0.97628571\n",
      " 0.97657143 0.97657143 0.97714286 0.97714286 0.97742857 0.97742857\n",
      " 0.978      0.978      0.97828571 0.97828571 0.97857143 0.97857143\n",
      " 0.97885714 0.97885714 0.97914286 0.97914286 0.97942857 0.97942857\n",
      " 0.97971429 0.97971429 0.98028571 0.98028571 0.98057143 0.98057143\n",
      " 0.98085714 0.98085714 0.98114286 0.98114286 0.98142857 0.98142857\n",
      " 0.98171429 0.98171429 0.982      0.982      0.98228571 0.98228571\n",
      " 0.98257143 0.98257143 0.98285714 0.98285714 0.98314286 0.98314286\n",
      " 0.98342857 0.98342857 0.98371429 0.98371429 0.984      0.984\n",
      " 0.98428571 0.98428571 0.98457143 0.98457143 0.98485714 0.98485714\n",
      " 0.98514286 0.98514286 0.98542857 0.98542857 0.98628571 0.98628571\n",
      " 0.98685714 0.98685714 0.98714286 0.98714286 0.98742857 0.98742857\n",
      " 0.98771429 0.98771429 0.988      0.988      0.98828571 0.98828571\n",
      " 0.98857143 0.98857143 0.98885714 0.98885714 0.98914286 0.98914286\n",
      " 0.98971429 0.98971429 0.99028571 0.99028571 0.99085714 0.99085714\n",
      " 0.99114286 0.99114286 0.99142857 0.99142857 0.99171429 0.99171429\n",
      " 0.992      0.992      0.99228571 0.99228571 0.99257143 0.99257143\n",
      " 0.99285714 0.99285714 0.99314286 0.99314286 0.99342857 0.99342857\n",
      " 0.99371429 0.99371429 0.994      0.994      0.99428571 0.99428571\n",
      " 0.99457143 0.99457143 0.99485714 0.99485714 0.99514286 0.99514286\n",
      " 0.99542857 0.99542857 0.99571429 0.99571429 0.996      0.996\n",
      " 0.99628571 0.99628571 0.99657143 0.99657143 0.99685714 0.99685714\n",
      " 0.99714286 0.99714286 0.99742857 0.99742857 0.99771429 0.99771429\n",
      " 0.998      0.998      0.99828571 0.99828571 0.99857143 0.99857143\n",
      " 1.        ]\n",
      "0.9953935487238375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35895, 20784)\n",
      "eval preds:\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0.00000000e+00 1.82681768e-04 1.82681768e-04 3.65363537e-04\n",
      " 3.65363537e-04 5.48045305e-04 5.48045305e-04 7.30727073e-04\n",
      " 7.30727073e-04 9.13408842e-04 9.13408842e-04 1.09609061e-03\n",
      " 1.09609061e-03 1.27877238e-03 1.27877238e-03 1.46145415e-03\n",
      " 1.46145415e-03 1.64413592e-03 1.64413592e-03 1.82681768e-03\n",
      " 1.82681768e-03 2.00949945e-03 2.00949945e-03 2.19218122e-03\n",
      " 2.19218122e-03 2.37486299e-03 2.37486299e-03 2.55754476e-03\n",
      " 2.55754476e-03 2.74022653e-03 2.74022653e-03 2.92290829e-03\n",
      " 2.92290829e-03 3.28827183e-03 3.28827183e-03 3.47095360e-03\n",
      " 3.47095360e-03 3.65363537e-03 3.65363537e-03 3.83631714e-03\n",
      " 3.83631714e-03 4.01899890e-03 4.01899890e-03 4.20168067e-03\n",
      " 4.20168067e-03 4.56704421e-03 4.56704421e-03 5.11508951e-03\n",
      " 5.11508951e-03 5.29777128e-03 5.29777128e-03 5.84581659e-03\n",
      " 5.84581659e-03 6.02849836e-03 6.02849836e-03 6.57654366e-03\n",
      " 6.57654366e-03 7.12458897e-03 7.12458897e-03 7.48995250e-03\n",
      " 7.48995250e-03 7.67263427e-03 7.67263427e-03 8.03799781e-03\n",
      " 8.03799781e-03 8.22067958e-03 8.22067958e-03 9.13408842e-03\n",
      " 9.13408842e-03 9.49945195e-03 9.49945195e-03 9.86481549e-03\n",
      " 9.86481549e-03 1.00474973e-02 1.00474973e-02 1.04128608e-02\n",
      " 1.04128608e-02 1.05955426e-02 1.05955426e-02 1.11435879e-02\n",
      " 1.11435879e-02 1.15089514e-02 1.15089514e-02 1.16916332e-02\n",
      " 1.16916332e-02 1.20569967e-02 1.20569967e-02 1.44318597e-02\n",
      " 1.44318597e-02 1.47972232e-02 1.47972232e-02 1.51625868e-02\n",
      " 1.51625868e-02 1.53452685e-02 1.53452685e-02 1.55279503e-02\n",
      " 1.55279503e-02 1.58933138e-02 1.58933138e-02 1.68067227e-02\n",
      " 1.68067227e-02 1.71720862e-02 1.71720862e-02 1.73547680e-02\n",
      " 1.73547680e-02 1.79028133e-02 1.79028133e-02 1.80854951e-02\n",
      " 1.80854951e-02 1.93642674e-02 1.93642674e-02 2.17391304e-02\n",
      " 2.17391304e-02 2.30179028e-02 2.30179028e-02 2.46620387e-02\n",
      " 2.46620387e-02 2.63061746e-02 2.63061746e-02 2.66715382e-02\n",
      " 2.66715382e-02 2.99598100e-02 2.99598100e-02 3.01424918e-02\n",
      " 3.01424918e-02 3.30654001e-02 3.30654001e-02 3.43441725e-02\n",
      " 3.43441725e-02 3.56229448e-02 3.56229448e-02 3.65363537e-02\n",
      " 3.65363537e-02 3.78151261e-02 3.78151261e-02 3.85458531e-02\n",
      " 3.85458531e-02 3.89112167e-02 3.89112167e-02 4.01899890e-02\n",
      " 4.01899890e-02 4.23821703e-02 4.23821703e-02 4.27475338e-02\n",
      " 4.27475338e-02 5.04201681e-02 5.04201681e-02 5.09682134e-02\n",
      " 5.09682134e-02 5.38911217e-02 5.38911217e-02 5.71793935e-02\n",
      " 5.71793935e-02 5.97369383e-02 5.97369383e-02 6.17464377e-02\n",
      " 6.17464377e-02 6.81402996e-02 6.81402996e-02 7.05151626e-02\n",
      " 7.05151626e-02 7.08805261e-02 7.08805261e-02 7.65436609e-02\n",
      " 7.65436609e-02 7.85531604e-02 7.85531604e-02 7.96492510e-02\n",
      " 7.96492510e-02 8.09280234e-02 8.09280234e-02 8.33028864e-02\n",
      " 8.33028864e-02 8.49470223e-02 8.49470223e-02 9.57252466e-02\n",
      " 9.57252466e-02 9.90135185e-02 9.90135185e-02 1.01388381e-01\n",
      " 1.01388381e-01 1.02119109e-01 1.02119109e-01 1.27694556e-01\n",
      " 1.27694556e-01 1.30069419e-01 1.30069419e-01 1.34819145e-01\n",
      " 1.34819145e-01 1.61308001e-01 1.61308001e-01 1.87979540e-01\n",
      " 1.87979540e-01 2.07343807e-01 2.07343807e-01 2.20496894e-01\n",
      " 2.20496894e-01 2.38034344e-01 2.38034344e-01 2.77310924e-01\n",
      " 2.77310924e-01 2.82060650e-01 2.82060650e-01 3.21337231e-01\n",
      " 3.21337231e-01 3.29740592e-01 1.00000000e+00] [0.         0.73306659 0.74364104 0.74364104 0.83852529 0.83852529\n",
      " 0.8871106  0.8871106  0.89739926 0.89739926 0.91368963 0.91368963\n",
      " 0.92197771 0.92197771 0.92340669 0.92340669 0.92569306 0.92569306\n",
      " 0.92655044 0.92655044 0.93055159 0.93055159 0.93198057 0.93198057\n",
      " 0.93855387 0.93855387 0.94627036 0.94627036 0.94712775 0.94712775\n",
      " 0.94798514 0.94798514 0.94827093 0.94827093 0.94969991 0.94969991\n",
      " 0.95198628 0.95198628 0.95227208 0.95227208 0.95455845 0.95455845\n",
      " 0.95713061 0.95713061 0.95827379 0.95827379 0.96113175 0.96113175\n",
      " 0.96256073 0.96256073 0.96284653 0.96284653 0.96341812 0.96341812\n",
      " 0.96370392 0.96370392 0.96398971 0.96398971 0.96541869 0.96541869\n",
      " 0.96599028 0.96599028 0.96941983 0.96941983 0.96970563 0.96970563\n",
      " 0.97142041 0.97142041 0.971992   0.971992   0.97227779 0.97227779\n",
      " 0.97284939 0.97284939 0.97313518 0.97313518 0.97427837 0.97427837\n",
      " 0.97456416 0.97456416 0.97570734 0.97570734 0.97656473 0.97656473\n",
      " 0.97742212 0.97742212 0.97770792 0.97770792 0.97799371 0.97799371\n",
      " 0.9785653  0.9785653  0.9791369  0.9791369  0.97970849 0.97970849\n",
      " 0.98085167 0.98085167 0.98113747 0.98113747 0.98142326 0.98142326\n",
      " 0.98199486 0.98199486 0.98256645 0.98256645 0.98285224 0.98285224\n",
      " 0.98313804 0.98313804 0.98342384 0.98342384 0.98370963 0.98370963\n",
      " 0.98399543 0.98399543 0.98456702 0.98456702 0.98485282 0.98485282\n",
      " 0.98513861 0.98513861 0.98542441 0.98542441 0.985996   0.985996\n",
      " 0.98628179 0.98628179 0.98685339 0.98685339 0.98713918 0.98713918\n",
      " 0.98799657 0.98799657 0.98828237 0.98828237 0.98856816 0.98856816\n",
      " 0.98885396 0.98885396 0.98913975 0.98913975 0.98942555 0.98942555\n",
      " 0.98971135 0.98971135 0.98999714 0.98999714 0.99028294 0.99028294\n",
      " 0.99056873 0.99056873 0.99085453 0.99085453 0.99114033 0.99114033\n",
      " 0.99142612 0.99142612 0.99171192 0.99171192 0.99199771 0.99199771\n",
      " 0.99228351 0.99228351 0.99256931 0.99256931 0.9928551  0.9928551\n",
      " 0.9931409  0.9931409  0.99342669 0.99342669 0.99371249 0.99371249\n",
      " 0.99399829 0.99399829 0.99428408 0.99428408 0.99456988 0.99456988\n",
      " 0.99485567 0.99485567 0.99514147 0.99514147 0.99542726 0.99542726\n",
      " 0.99571306 0.99571306 0.99599886 0.99599886 0.99628465 0.99628465\n",
      " 0.99657045 0.99657045 0.99685624 0.99685624 0.99714204 0.99714204\n",
      " 0.99742784 0.99742784 0.99771363 0.99771363 0.99799943 0.99799943\n",
      " 0.99828522 0.99828522 1.        ]\n",
      "0.997091005593435\n",
      "(35895, 20784)\n",
      "eval preds:\n",
      "[0.62355721 0.         0.51439337 ... 0.63553024 0.69046879 0.52427968]\n",
      "[0.         0.00164414 0.00164414 ... 0.63244428 0.66569236 1.        ] [0.         0.30580166 0.31494713 ... 0.99914261 0.99914261 1.        ]\n",
      "0.9468253521570912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "## cv split\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "skf.get_n_splits(tf_train, y_train)\n",
    "\n",
    "aus_list = []\n",
    "for i, (train_idx, test_idx) in enumerate(skf.split(tf_train, y_train)):\n",
    "    train_X = tf_train[train_idx]\n",
    "    eval_X = tf_train[test_idx];\n",
    "    train_y = y_train[train_idx]\n",
    "    eval_y = y_train[test_idx];\n",
    "    \n",
    "    print(train_X.shape)\n",
    "    ensemble.fit(train_X, train_y)\n",
    "    joblib.dump(clf, f'{model_path}clf_cv_{i}.pkl');\n",
    "    joblib.dump(sgd_model, f'{model_path}sgd_model_cv_{i}.pkl')\n",
    "    joblib.dump(lgb, f'{model_path}lgb_cv_{i}.pkl')\n",
    "    joblib.dump(cat, f'{model_path}cat_cv_{i}.pkl')\n",
    "    joblib.dump(ensemble, f'{model_path}ensemble_cv_{i}.pkl');\n",
    "    eval_preds = ensemble.predict_proba(eval_X)[:,1]\n",
    "    #eval_preds = ensemble.predict(eval_X)\n",
    "    print('eval preds:');\n",
    "    print(eval_preds)\n",
    "    ## compute AUC\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(eval_y, eval_preds, pos_label = 1)\n",
    "    print(fpr, tpr)\n",
    "    print(metrics.auc(fpr, tpr))\n",
    "    aus_list.append(metrics.auc(fpr, tpr))\n",
    "    #break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d27f017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn \n",
    "import lightgbm\n",
    "display(sklearn.__version__)\n",
    "display(lightgbm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4185a33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9966875336854236,\n",
       " 0.9941866485724724,\n",
       " 0.9953935487238375,\n",
       " 0.997091005593435,\n",
       " 0.9468253521570912]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment with only sgb classifier, original parameter setting\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65f99c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9951818197240959,\n",
       " 0.988915444438645,\n",
       " 0.9920609113210502,\n",
       " 0.9955969986936087,\n",
       " 0.9605266936228868]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment with only catboost, original parameter setting\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6823c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9978818736207736,\n",
       " 0.9945432433843102,\n",
       " 0.9961483897906989,\n",
       " 0.9974760260852231,\n",
       " 0.9665304445771498]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=4.893256185259296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.893256185259296\n",
      "[LightGBM] [Warning] num_iterations is set=1500, n_iter=1500 will be ignored. Current value: num_iterations=1500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=115, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=115\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.562963348932286, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.562963348932286\n"
     ]
    }
   ],
   "source": [
    "# experiment with only lightgbm 4, with cpu max bin 900 and max_depth 123\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5df45864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9633644054857161,\n",
       " 0.9755928284357223,\n",
       " 0.9867114150007829,\n",
       " 0.9750459523745131,\n",
       " 0.7752189335791227]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment with only lightgbm 3\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77674e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9980322623163044,\n",
       " 0.994754319118952,\n",
       " 0.9964657341197348,\n",
       " 0.9976234663006696,\n",
       " 0.9670913856801093]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment with only lightgbm2, depth 23\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e08819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9980014642148245,\n",
       " 0.9947916383944883,\n",
       " 0.9964219426901196,\n",
       " 0.9976602219351152,\n",
       " 0.9670607907912099]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment with only lightgbm, max_bin 250, max-depth = 123\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "300f3aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9979935819888527,\n",
       " 0.9949521895714809,\n",
       " 0.9962090923325854,\n",
       " 0.997664973018545,\n",
       " 0.966284693481503]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment wiht only lightgbm, max_bin 200\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e5ef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9974415651699572,\n",
       " 0.9950194686570281,\n",
       " 0.996574873427632,\n",
       " 0.9978453575597517,\n",
       " 0.9644704583375404]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8.562963348932286, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.562963348932286\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.893256185259296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.893256185259296\n",
      "[LightGBM] [Warning] num_iterations is set=1500, n_iter=1500 will be ignored. Current value: num_iterations=1500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=115, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=115\n"
     ]
    }
   ],
   "source": [
    "#experiment without catboost\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e542d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9976213425623237,\n",
       " 0.9957595907928388,\n",
       " 0.9970352314838978,\n",
       " 0.9979617852086347,\n",
       " 0.9608195900848752]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168a6717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9948483859465849,\n",
       " 0.9940963507093242,\n",
       " 0.9947070055108838,\n",
       " 0.9951455995069962,\n",
       " 0.9753977531773758]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## with external data\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8499b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9974293503297094,\n",
       " 0.9950473406754007,\n",
       " 0.9966961219270317,\n",
       " 0.9978349678278557,\n",
       " 0.9645059087292857]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## without external data\n",
    "aus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db0a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
