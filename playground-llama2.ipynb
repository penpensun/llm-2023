{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c65bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 14:37:39.254268: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-06 14:37:39.254341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-06 14:37:39.254377: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-06 14:37:39.264500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForSequenceClassification, LlamaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f64b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['WANDB_PROJECT'] = 'kaggle-llm-2023-llama-2-7b-test-train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589b22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = '/home/peng_sun2/s3shared/kaggle/llm-2023/Llama-2-7b-chat-hf/config'\n",
    "tokenizer_dir = '/home/peng_sun2/s3shared/kaggle/llm-2023/Llama-2-7b-chat-hf/tokenizer'\n",
    "model_dir = '/home/peng_sun2/s3shared/kaggle/llm-2023/Llama-2-7b-chat-hf/model'\n",
    "config= LlamaConfig.from_pretrained(config_dir)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(tokenizer_dir)\n",
    "\n",
    "## set up the pad token\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.padding_side = \"left\"\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "## set up the number of labels\n",
    "config.num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abfa75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023559093475341797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a258408679cf42fea4f6465e0e10607b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForSequenceClassification.from_pretrained(model_dir, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0448c528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.tokenization_llama.LlamaTokenizer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5ce996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer, config):\n",
    "    sep = tokenizer.sep_token\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        padding = True,\n",
    "        truncation = True,\n",
    "        max_length = 1600\n",
    "    )\n",
    "    return {\n",
    "        **tokenized\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b28a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentence = \"This is a test sentence\"\n",
    "text_sent_tok = tokenize(text_sentence, tokenizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d943fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_tensor = {\n",
    "    'input_ids':torch.tensor(text_sent_tok['input_ids'], dtype = torch.long).view(1, -1),\n",
    "    'attention_mask': torch.tensor(text_sent_tok['attention_mask'], dtype= torch.long).view(1, -1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7796b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(input_ids = input_tensor['input_ids'], \n",
    "      attention_mask = input_tensor['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473f391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.3142, -4.3097]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4856cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import HfArgumentParser\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a370b",
   "metadata": {},
   "source": [
    "## Read in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9dfe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12981dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(18894, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/test_essays.csv')\n",
    "sub = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/sample_submission.csv')\n",
    "org_train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/train_essays.csv')\n",
    "\n",
    "train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/daigt/train_v2_drcat_02.csv', sep=',')\n",
    "display(train.shape);\n",
    "\n",
    "train_gen_data = pd.read_parquet('/home/peng_sun2/s3shared/kaggle/llm-2023/external_data/gen_data_21122023.parquet')\n",
    "display(train_gen_data.shape)\n",
    "\n",
    "train = train.drop_duplicates(subset = ['text'])\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "\n",
    "### append the generated data\n",
    "# train = pd.concat([train, train_gen_data], axis = 0).reset_index(drop = True)\n",
    "# display(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679af0d",
   "metadata": {},
   "source": [
    "## Split the training data using groupkfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f413f733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Phones\\n\\nModern humans today are always on th...      0   \n",
       "1  This essay will explain if drivers should or s...      0   \n",
       "2  Driving while the use of cellular devices\\n\\nT...      0   \n",
       "\n",
       "          prompt_name           source  RDizzl3_seven  \n",
       "0  Phones and driving  persuade_corpus          False  \n",
       "1  Phones and driving  persuade_corpus          False  \n",
       "2  Phones and driving  persuade_corpus          False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a04e33ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_kfold = GroupKFold(n_splits = 5)\n",
    "groups = train.prompt_name\n",
    "group_kfold.get_n_splits(train['text'], train['label'], groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eece6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_train(df, tokenizer):\n",
    "    tokenized = tokenizer(\n",
    "        df['text'],\n",
    "        padding = True,\n",
    "        truncation = True,\n",
    "        max_length = 1600\n",
    "    )\n",
    "    \n",
    "    labels = df['label']\n",
    "    return {\n",
    "        **tokenized,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b0619fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: \n",
      "Train index shape: (35612,), group = ['Car-free cities' 'Summer projects' '\"A Cowboy Who Rode the Waves\"'\n",
      " 'Mandatory extracurricular activities' 'Exploring Venus'\n",
      " 'Facial action coding system' 'The Face on Mars' 'Community service'\n",
      " 'Grades for extracurricular activities' 'Driverless cars'\n",
      " 'Does the electoral college work?' 'Seeking multiple opinions']\n",
      "Test index shape: (9256,), group = ['Phones and driving' 'Cell phones at school' 'Distance learning']\n",
      "Fold 1: \n",
      "Train index shape: (35623,), group = ['Phones and driving' 'Car-free cities' 'Summer projects'\n",
      " '\"A Cowboy Who Rode the Waves\"' 'Mandatory extracurricular activities'\n",
      " 'Facial action coding system' 'Community service'\n",
      " 'Grades for extracurricular activities' 'Driverless cars'\n",
      " 'Does the electoral college work?' 'Cell phones at school'\n",
      " 'Distance learning']\n",
      "Test index shape: (9245,), group = ['Exploring Venus' 'The Face on Mars' 'Seeking multiple opinions']\n",
      "Fold 2: \n",
      "Train index shape: (35809,), group = ['Phones and driving' 'Summer projects' '\"A Cowboy Who Rode the Waves\"'\n",
      " 'Mandatory extracurricular activities' 'Exploring Venus'\n",
      " 'Facial action coding system' 'The Face on Mars'\n",
      " 'Grades for extracurricular activities'\n",
      " 'Does the electoral college work?' 'Cell phones at school'\n",
      " 'Distance learning' 'Seeking multiple opinions']\n",
      "Test index shape: (9059,), group = ['Car-free cities' 'Community service' 'Driverless cars']\n",
      "Fold 3: \n",
      "Train index shape: (35837,), group = ['Phones and driving' 'Car-free cities'\n",
      " 'Mandatory extracurricular activities' 'Exploring Venus'\n",
      " 'Facial action coding system' 'The Face on Mars' 'Community service'\n",
      " 'Grades for extracurricular activities' 'Driverless cars'\n",
      " 'Cell phones at school' 'Distance learning' 'Seeking multiple opinions']\n",
      "Test index shape: (9031,), group = ['Summer projects' '\"A Cowboy Who Rode the Waves\"'\n",
      " 'Does the electoral college work?']\n",
      "Fold 4: \n",
      "Train index shape: (36591,), group = ['Phones and driving' 'Car-free cities' 'Summer projects'\n",
      " '\"A Cowboy Who Rode the Waves\"' 'Exploring Venus' 'The Face on Mars'\n",
      " 'Community service' 'Driverless cars' 'Does the electoral college work?'\n",
      " 'Cell phones at school' 'Distance learning' 'Seeking multiple opinions']\n",
      "Test index shape: (8277,), group = ['Mandatory extracurricular activities' 'Facial action coding system'\n",
      " 'Grades for extracurricular activities']\n"
     ]
    }
   ],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(group_kfold.split(train['text'], train['label'], groups)):\n",
    "    print(f'Fold {i}: ')\n",
    "    print(f'Train index shape: {train_idx.shape}, group = {groups[train_idx].unique()}')\n",
    "    print(f'Test index shape: {test_idx.shape}, group = {groups[test_idx].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b35a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, disable_progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ead3011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023759841918945312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35612,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fff37c9b6b483ea3861ca45ba72d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35612 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021152973175048828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35612,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a125fad7c14b69acd0e0f1faca5b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35612 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02407217025756836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35623,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a484e7dc273442aa9ccdbd12bc7e2511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02226114273071289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35623,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f1c6095ebd4d1790456790e44bc8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02314019203186035,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35809,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eaad64e3fcf4c44b7dc2d7c8552b897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021653413772583008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35809,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad1bf4664614c9eade33eaa44590dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022504568099975586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35837,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23999621b429463087c7be03341e952e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35837 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02246999740600586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 35837,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d3fac77bb0481ab40d3d3ec6996d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35837 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022260665893554688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 36591,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdb7b0c42544cb59edfd06d27964bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/36591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02156519889831543,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 36591,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46b9f53da2b4cfb9db6496cb49abd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/36591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(group_kfold.split(train['text'], train['label'], groups)):\n",
    "    train_ds = Dataset.from_pandas(train.loc[train_idx, :])\n",
    "    val_ds = Dataset.from_pandas(train.loc[test_idx, :])\n",
    "    \n",
    "    train_ds = train_ds.map(\n",
    "        tokenize_train,\n",
    "        batched = False,\n",
    "        num_proc = 4,\n",
    "        fn_kwargs = {'tokenizer': tokenizer}\n",
    "    )\n",
    "    \n",
    "    val_ds = train_ds.map(\n",
    "        tokenize_train,\n",
    "        batched = False,\n",
    "        num_proc = 4,\n",
    "        fn_kwargs = {'tokenizer': tokenizer}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "166ad290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer = tokenizer,\n",
    "    pad_to_multiple_of=16 ,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fc3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    add_prompt_text: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata = {\"help\": \"Add prompt text into input.\"}\n",
    "    )\n",
    "    \n",
    "    max_seq_length: Optional[int] = field(\n",
    "        default = 1600,\n",
    "        metadata = {'help': 'max sequence length'}\n",
    "    )\n",
    "    fold: Optional[int] = field(\n",
    "        default=0,\n",
    "        metadata={\"help\": \"Fold\"},\n",
    "    )\n",
    "\n",
    "    num_proc: Optional[int] = field(\n",
    "        default=4,\n",
    "        metadata={\"help\": \"Number of processes\"},\n",
    "    )\n",
    "\n",
    "    dropout: Optional[float] = field(\n",
    "        default=0.,\n",
    "        metadata={\"help\": \"Amount of dropout to apply\"},\n",
    "    )\n",
    "    max_position_embeddings: Optional[int] = field(\n",
    "        default=1600,\n",
    "        #default=512,\n",
    "        #default = 512,\n",
    "        metadata={\"help\": \"Amount of dropout to apply\"},\n",
    "    ) \n",
    "        \n",
    "    data_dir: Optional[str] = field(\n",
    "        default=\"./\",\n",
    "        metadata={\"help\": \"Data directory\"},\n",
    "    )\n",
    "        \n",
    "    max_seq_length: Optional[int] = field(\n",
    "        default=1600,\n",
    "        #default = 512,\n",
    "        #default = 512,\n",
    "        metadata={\"help\": \"Max sequence length\"},\n",
    "    )\n",
    "\n",
    "    add_prompt_question: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Add prompt question into input\"},\n",
    "    )\n",
    "\n",
    "    add_prompt_text: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Add prompt text into input\"},\n",
    "    )\n",
    "\n",
    "    fold: Optional[int] = field(\n",
    "        default=0,\n",
    "        metadata={\"help\": \"Fold\"},\n",
    "    )\n",
    "\n",
    "    num_proc: Optional[int] = field(\n",
    "        default=4,\n",
    "        metadata={\"help\": \"Number of processes\"},\n",
    "    )\n",
    "\n",
    "    dropout: Optional[float] = field(\n",
    "        default=0.,\n",
    "        metadata={\"help\": \"Amount of dropout to apply\"},\n",
    "    )\n",
    "    max_position_embeddings: Optional[int] = field(\n",
    "        default=1600,\n",
    "        #default=512,\n",
    "        #default = 512,\n",
    "        metadata={\"help\": \"Amount of dropout to apply\"},\n",
    "    )\n",
    "        \n",
    "#     output_dir: Optional[str] = field(\n",
    "#         default= \"./\",\n",
    "#         metadata={\"help\": \"Output directory\"}\n",
    "#     )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c25241f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({\n",
    "    'hidden_dropout_prob': 0,\n",
    "    'attention_probs_dropout_prob': 0,\n",
    "    'num_labels': 2,\n",
    "    'problem_type': 'single_label_classification',\n",
    "    'max_position_embeddings': 1600,\n",
    "    'num_proc': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b63bac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(18894, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(44868, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('/home/peng_sun2/s3shared/kaggle/llm-2023/data/daigt/train_v2_drcat_02.csv', sep=',')\n",
    "display(train.shape);\n",
    "\n",
    "train_gen_data = pd.read_parquet('/home/peng_sun2/s3shared/kaggle/llm-2023/external_data/gen_data_21122023.parquet')\n",
    "display(train_gen_data.shape)\n",
    "\n",
    "train = train.drop_duplicates(subset = ['text'])\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "display(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f969b39",
   "metadata": {},
   "source": [
    "### Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12e9d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def compute_auc(eval_pred):\n",
    "    preds, labels = eval_pred;\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, preds, pos_label = 1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return {\n",
    "        'auc': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aaec4a",
   "metadata": {},
   "source": [
    "### Test train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b92cc86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train.iloc[:30000, :])\n",
    "val_ds = Dataset.from_pandas(train.iloc[30000:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3a59251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02408599853515625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 30000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e10ef1bbcb9478fb09b0def4884ff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023671627044677734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map (num_proc=4)",
       "rate": null,
       "total": 14868,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59097a686e5b4b3c9919b546379c9561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/14868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.map(\n",
    "    tokenize_train,\n",
    "    batched = False,\n",
    "    num_proc = config.num_proc,\n",
    "    fn_kwargs = {'tokenizer': tokenizer}\n",
    ")\n",
    "\n",
    "val_ds = val_ds.map(\n",
    "    tokenize_train,\n",
    "    batched = False,\n",
    "    num_proc = config.num_proc,\n",
    "    fn_kwargs = {'tokenizer': tokenizer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe4ec2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenize_train,\n",
    "        pad_to_multiple_of=16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a59fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Output directory for model checkpoints and predictions\n",
    "    num_train_epochs=4,       # Number of training epochs\n",
    "    per_device_train_batch_size=8,  # Batch size per GPU/TPU core for training\n",
    "    per_device_eval_batch_size=8,   # Batch size per GPU/TPU core for evaluation\n",
    "    learning_rate=6e-6,\n",
    "    weight_decay=1e-4,        # Weight decay for regularization\n",
    "    warmup_ratio=0,\n",
    "    lr_scheduler_type='cosine',\n",
    "    optim='adamw_torch',\n",
    "    logging_dir='./logs',     # Directory for Tensorboard logs\n",
    "    logging_strategy='steps',  # Log every `logging_steps`\n",
    "    logging_steps=150,         # Log every 100 steps\n",
    "    evaluation_strategy='steps',  # Evaluate every `eval_steps`\n",
    "    eval_steps=150,             # Evaluate every 500 steps\n",
    "    save_strategy='epoch',      # Save a checkpoint every epoch\n",
    "    save_total_limit=1,\n",
    "    save_steps=150,            # Save a checkpoint every 1000 steps\n",
    "    report_to=\"wandb\",          # Integration with Weights & Biases for logging\n",
    "    run_name=\"test-llm-2023-llama2-run\",     # Name for the current run\n",
    "    metric_for_best_model='auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97934ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 15.78 GiB total capacity; 14.72 GiB already allocated; 81.94 MiB free; 14.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m----> 3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcompute_auc\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:509\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    508\u001b[0m ):\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:733\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 733\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:2058\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2056\u001b[0m     )\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 641 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 15.78 GiB total capacity; 14.72 GiB already allocated; 81.94 MiB free; 14.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = val_ds,\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f85813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
